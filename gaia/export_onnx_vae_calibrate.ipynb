{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbernddoser\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/doserbd/git/Spherinator/gaia/wandb/run-20250215_173715-6by98yrh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bernddoser/Spherinator-gaia/runs/6by98yrh' target=\"_blank\">spellbinding-cupid-46</a></strong> to <a href='https://wandb.ai/bernddoser/Spherinator-gaia' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bernddoser/Spherinator-gaia' target=\"_blank\">https://wandb.ai/bernddoser/Spherinator-gaia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bernddoser/Spherinator-gaia/runs/6by98yrh' target=\"_blank\">https://wandb.ai/bernddoser/Spherinator-gaia/runs/6by98yrh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Registries can be linked/fetched using a shorthand form without specifying the organization name. Try using shorthand path format: <my_registry_name>/<artifact_name> or just <my_registry_name> if fetching just the project.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/doserbd/git/Spherinator/gaia/artifacts/model-qf4roy5i:v0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('ain-space-org/wandb-registry-model/gaia calibrated:v0', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# import importlib\n",
    "\n",
    "# config = yaml.load(open('model.yaml'), Loader=yaml.FullLoader)\n",
    "# model_class_path = config[\"model\"][\"class_path\"]\n",
    "# module_name, class_name = model_class_path.rsplit(\".\", 1)\n",
    "# module = importlib.import_module(module_name)\n",
    "# model_class = getattr(module, class_name)\n",
    "# model_init_args = config[\"model\"][\"init_args\"]\n",
    "# model = model_class(**model_init_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[-0.4091,  0.9021, -0.1373]], grad_fn=<DivBackward0>),\n",
       "  tensor([[1.6134]], grad_fn=<AddBackward0>)),\n",
       " (PowerSpherical(loc: torch.Size([1, 3]), scale: 1.6133633852005005),\n",
       "  HypersphericalUniform(dim=3, device=cpu, dtype=torch.float32)),\n",
       " tensor([[0.2436, 0.8303, 0.5012]], grad_fn=<SubBackward0>),\n",
       " tensor([[[-6.8057e-03,  1.9459e-02, -5.3595e-02, -3.7205e-02, -2.3930e-02,\n",
       "           -5.9241e-02, -1.8189e-02, -5.7850e-02,  6.2767e-02,  1.3388e-03,\n",
       "           -2.4770e-02, -1.9696e-02, -8.3411e-02,  1.4066e-02,  1.2744e-02,\n",
       "            1.1135e-01,  6.4969e-02,  3.3827e-02, -3.3790e-02,  5.3837e-02,\n",
       "            2.1002e-02,  4.9876e-02, -5.6155e-02,  1.1612e-02,  2.3143e-03,\n",
       "            8.6934e-02, -9.7613e-02, -3.5659e-02,  3.8975e-02,  6.6614e-02,\n",
       "           -3.3168e-03,  1.0015e-03,  1.0494e-01,  7.9843e-02,  1.2305e-01,\n",
       "           -3.4582e-02,  2.4456e-03, -6.8078e-02,  1.3040e-02, -2.1108e-02,\n",
       "           -4.7508e-02,  7.1821e-02,  5.3122e-02, -2.5421e-02, -5.0033e-02,\n",
       "           -5.2340e-02,  5.0061e-02,  9.2812e-03, -6.9518e-03, -6.1605e-03,\n",
       "            1.4116e-01,  1.1066e-02,  6.6505e-02, -1.6798e-01, -1.3004e-02,\n",
       "            4.9592e-02,  8.3337e-02, -1.8530e-03, -7.2705e-02, -1.9630e-02,\n",
       "           -3.7321e-02, -4.8375e-02, -1.9707e-03,  1.3722e-02,  4.8836e-02,\n",
       "            7.2437e-02, -4.2112e-02,  9.6549e-02,  5.3990e-02, -1.1627e-01,\n",
       "           -4.1010e-02,  9.1606e-03,  3.3118e-02, -1.6115e-01, -6.3099e-02,\n",
       "           -1.5826e-03, -8.5194e-02,  9.7161e-03,  5.0068e-02, -1.3327e-01,\n",
       "           -9.4198e-02,  6.6205e-02, -3.9063e-03, -1.9069e-02,  1.4931e-01,\n",
       "           -4.9802e-02, -1.0392e-02,  1.0556e-01,  3.1261e-02, -6.9236e-02,\n",
       "           -7.6929e-02,  4.0476e-02,  2.9095e-02,  3.3778e-02, -9.4859e-02,\n",
       "           -9.5760e-02,  1.0379e-01, -1.6017e-01,  1.8036e-02,  1.4768e-01,\n",
       "           -1.2645e-02, -1.4011e-01,  6.2634e-02,  8.4731e-02,  3.2948e-02,\n",
       "            9.5426e-02, -9.6514e-02,  5.4009e-02,  7.2130e-02, -3.1780e-02,\n",
       "            2.0012e-03,  6.5523e-02,  2.3198e-02,  3.6750e-02,  7.6100e-02,\n",
       "            6.5743e-02,  7.9155e-02, -1.8240e-02,  4.2387e-02,  5.2722e-02,\n",
       "           -7.9189e-03,  9.6025e-02,  5.0384e-02,  9.3282e-02, -5.6017e-02,\n",
       "            6.2726e-02,  5.3226e-02, -7.5364e-02, -4.9195e-02, -4.3316e-04,\n",
       "            1.9691e-02,  5.4951e-02, -1.3168e-02, -1.9234e-02,  8.0251e-02,\n",
       "            2.6604e-04,  1.6324e-02,  9.0776e-02, -1.4989e-01,  9.1732e-02,\n",
       "           -6.6115e-02, -1.4588e-02,  2.7949e-02,  2.5429e-02, -1.6339e-02,\n",
       "            1.6522e-02, -4.6592e-02,  3.4310e-02,  1.3368e-02, -6.7486e-02,\n",
       "            3.0886e-02,  3.2567e-02, -2.6056e-02,  2.2969e-02, -4.5513e-02,\n",
       "            6.1560e-02,  8.5075e-02, -1.3614e-02, -3.4630e-02, -3.4893e-02,\n",
       "            1.0884e-01,  2.5087e-03,  8.9720e-02, -7.5325e-02,  5.6390e-02,\n",
       "           -1.5086e-01,  1.1311e-01,  5.2445e-02,  5.8523e-02,  3.1291e-02,\n",
       "            9.1947e-02,  7.0222e-02,  2.9255e-02,  7.5385e-02, -3.2221e-02,\n",
       "           -5.1776e-02, -6.9603e-02, -1.8022e-01,  9.4673e-02,  2.1576e-02,\n",
       "           -2.0051e-03,  1.6663e-02,  3.9241e-02,  3.6812e-02,  7.3846e-03,\n",
       "            1.0726e-01,  6.4781e-02, -5.2142e-02, -8.4479e-02,  3.6012e-02,\n",
       "           -8.4148e-02, -5.9918e-02,  8.3669e-02,  5.8531e-03, -5.7563e-02,\n",
       "            3.7796e-02,  5.1074e-02,  6.2805e-02, -1.0023e-02,  3.9632e-02,\n",
       "            4.4580e-02, -1.9032e-02, -9.4947e-02, -2.9153e-02, -8.5647e-03,\n",
       "            5.1058e-02, -2.7585e-02, -3.4558e-02,  3.3375e-02,  3.5034e-02,\n",
       "            4.2704e-02, -2.4817e-02, -3.8477e-02,  7.9358e-02,  1.9371e-02,\n",
       "           -8.2516e-02,  5.9831e-02,  7.8221e-02,  3.9066e-02,  2.8449e-02,\n",
       "           -2.4708e-02, -1.0395e-02, -6.8954e-03,  3.0247e-02, -9.8477e-03,\n",
       "            8.7127e-02, -2.9147e-02, -2.3150e-02,  1.6459e-02,  3.3749e-02,\n",
       "            1.1245e-01, -1.1552e-01,  1.1536e-02, -7.7727e-02, -2.8372e-02,\n",
       "           -8.6132e-02,  2.3691e-02,  3.4579e-03,  6.6962e-02,  9.9656e-03,\n",
       "           -4.0964e-02,  6.8836e-02, -1.0956e-01, -7.9713e-02,  3.3738e-02,\n",
       "           -3.6313e-03, -5.2637e-03,  4.5095e-02, -5.5087e-02,  2.0666e-02,\n",
       "           -9.6527e-02,  7.4367e-03,  3.2106e-02,  7.6328e-02, -5.8316e-02,\n",
       "           -4.4877e-02, -1.0364e-02,  2.1336e-02, -2.4864e-02,  7.1797e-02,\n",
       "           -6.4984e-02, -3.6851e-02,  7.2126e-02,  1.4700e-02, -6.0320e-02,\n",
       "            7.6881e-02, -1.2093e-01, -9.5579e-02, -1.2818e-01, -8.0411e-03,\n",
       "           -1.5336e-02,  1.0714e-01,  8.1441e-02,  5.8677e-02, -1.1300e-02,\n",
       "           -6.1050e-02, -1.3559e-01,  4.3627e-03, -9.2477e-02, -2.4610e-02,\n",
       "           -9.8946e-03,  6.4693e-03, -1.5173e-02, -5.1318e-03, -4.3432e-02,\n",
       "            9.4196e-03,  8.5275e-02,  4.9297e-02, -8.6794e-02, -2.5843e-02,\n",
       "           -1.0784e-01,  2.8027e-02,  4.7830e-02, -3.6023e-02,  7.9593e-02,\n",
       "           -1.2504e-01,  6.2331e-02, -2.3045e-02, -7.9569e-02, -5.9710e-02,\n",
       "           -4.1920e-02, -8.5198e-02, -1.6493e-02,  1.3534e-02,  7.6377e-02,\n",
       "           -8.6270e-03,  1.6672e-02,  4.5527e-02, -1.3529e-02, -2.2211e-02,\n",
       "           -1.7218e-02,  2.7062e-02, -8.4716e-03,  5.0075e-02, -2.0337e-02,\n",
       "            6.5291e-02,  1.4886e-01, -1.7768e-02,  6.4424e-02, -6.1406e-02,\n",
       "           -5.1321e-02,  1.9620e-02, -3.2639e-02,  1.6437e-01,  1.2609e-01,\n",
       "           -7.6143e-02, -7.6860e-03,  1.2941e-01, -9.2095e-02, -1.8817e-02,\n",
       "            5.4285e-02, -3.2273e-02,  3.6731e-02, -1.6595e-04, -7.1791e-02,\n",
       "           -5.4893e-02,  6.6292e-02, -2.6270e-02, -2.6800e-02,  1.2321e-01,\n",
       "            1.1145e-02, -5.8114e-02, -1.8769e-02]]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from spherinator.models import (\n",
    "    ConsecutiveConv1DLayer,\n",
    "    ConvolutionalEncoder1DGen,\n",
    "    DenseModel,\n",
    "    VariationalAutoencoderPure,\n",
    ")\n",
    "\n",
    "cnn_layers=[ConsecutiveConv1DLayer(kernel_size=5,\n",
    "                                   num_layers=1,\n",
    "                                   base_channel_number=16,\n",
    "                                   pooling=torch.nn.MaxPool1d(2, ceil_mode=True)),\n",
    "            ConsecutiveConv1DLayer(kernel_size=7,\n",
    "                                   num_layers=1,\n",
    "                                   base_channel_number=32,\n",
    "                                   pooling=torch.nn.MaxPool1d(2, ceil_mode=True)),\n",
    "            ConsecutiveConv1DLayer(kernel_size=9,\n",
    "                                   num_layers=1,\n",
    "                                   base_channel_number=64,\n",
    "                                   pooling=torch.nn.MaxPool1d(2, ceil_mode=True))]\n",
    "encoder = ConvolutionalEncoder1DGen(input_dim=[1, 343],\n",
    "                                    output_dim=3,\n",
    "                                    cnn_layers=cnn_layers)\n",
    "decoder = DenseModel(layer_dims=[3, 16, 64, 256, 343],\n",
    "                     output_shape=[1, 343])\n",
    "model = VariationalAutoencoderPure(encoder=encoder,\n",
    "                                   decoder=decoder,\n",
    "                                   z_dim=3,\n",
    "                                   beta=1.0e-3)\n",
    "\n",
    "input = torch.randn(1, 1, 343)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 185,\n",
       " 'global_step': 44082,\n",
       " 'pytorch-lightning_version': '2.5.0.post0',\n",
       " 'state_dict': OrderedDict([('encoder.cnn.0.0.0.weight',\n",
       "               tensor([[[-0.2702, -0.5835, -0.2809, -0.2388, -0.2410]],\n",
       "               \n",
       "                       [[ 0.1957,  0.2095, -0.1171,  0.0027, -0.3216]],\n",
       "               \n",
       "                       [[-0.1548,  0.4688,  0.3817, -0.3931, -0.1283]],\n",
       "               \n",
       "                       [[-0.4041,  0.3574, -0.3008,  0.1009, -0.1252]],\n",
       "               \n",
       "                       [[-0.5530,  0.3542,  0.4249, -0.3230, -0.2633]],\n",
       "               \n",
       "                       [[-0.1498, -0.3973,  0.0577,  0.4716, -0.1178]],\n",
       "               \n",
       "                       [[-0.3342, -0.0057, -0.1332, -0.2695, -0.5383]],\n",
       "               \n",
       "                       [[ 0.4483, -0.2075, -0.2363, -0.2981,  0.3196]],\n",
       "               \n",
       "                       [[ 0.1340, -0.2998,  0.4229, -0.3330,  0.1517]],\n",
       "               \n",
       "                       [[-0.3221, -0.3529, -0.1921, -0.4498, -0.0400]],\n",
       "               \n",
       "                       [[ 0.4506,  0.5530,  0.3369,  0.1712, -0.0774]],\n",
       "               \n",
       "                       [[-0.3510,  0.2604, -0.0499, -0.2186,  0.3642]],\n",
       "               \n",
       "                       [[-0.3944,  0.1938, -0.4185, -0.0981, -0.1930]],\n",
       "               \n",
       "                       [[-0.3920,  0.0249, -0.1904,  0.1422, -0.1057]],\n",
       "               \n",
       "                       [[ 0.1744,  0.3259, -0.0861, -0.3786,  0.6779]],\n",
       "               \n",
       "                       [[-0.4510, -0.0430,  0.0474,  0.2054, -0.1969]]])),\n",
       "              ('encoder.cnn.0.0.0.bias',\n",
       "               tensor([ 0.4592, -0.2009,  0.0247,  0.1589,  0.2229, -0.0890,  0.3721,  0.2018,\n",
       "                        0.5668,  0.1027, -0.0395,  0.2214,  0.0700, -0.3394,  0.3707, -0.3069])),\n",
       "              ('encoder.cnn.0.0.1.weight',\n",
       "               tensor([0.8557, 0.8183, 0.6639, 0.7765, 0.9407, 0.5031, 0.8668, 0.6651, 1.3258,\n",
       "                       0.6958, 0.9750, 1.0119, 0.9012, 0.8772, 1.3174, 0.5979])),\n",
       "              ('encoder.cnn.0.0.1.bias',\n",
       "               tensor([ 0.0074,  0.0758,  0.3050, -0.1588,  0.4276, -0.2509,  0.0278,  0.2762,\n",
       "                       -0.4893, -0.6007,  0.1819,  0.2978, -0.3047, -0.3658, -0.0686,  0.1659])),\n",
       "              ('encoder.cnn.0.0.1.running_mean',\n",
       "               tensor([-0.6133, -0.2228,  0.1381, -0.0899, -0.0150, -0.1830, -0.4798,  0.2178,\n",
       "                        0.6185, -0.8007,  0.9122,  0.2298, -0.5346, -0.6904,  0.8512, -0.6004])),\n",
       "              ('encoder.cnn.0.0.1.running_var',\n",
       "               tensor([0.1332, 0.0011, 0.0035, 0.0072, 0.0084, 0.0026, 0.0834, 0.0018, 0.0003,\n",
       "                       0.0942, 0.1072, 0.0004, 0.0418, 0.0144, 0.0267, 0.0108])),\n",
       "              ('encoder.cnn.0.0.1.num_batches_tracked', tensor(44082)),\n",
       "              ('encoder.cnn.1.0.0.weight',\n",
       "               tensor([[[ 2.6956e-01,  1.3200e-01,  1.4546e-01,  ...,  1.2638e-02,\n",
       "                         -1.8367e-01, -2.4225e-01],\n",
       "                        [-1.2385e-01, -3.9293e-02,  1.2478e-01,  ..., -1.0693e-01,\n",
       "                         -4.7730e-02, -1.8425e-01],\n",
       "                        [-7.8778e-02, -1.6643e-01, -1.4380e-01,  ..., -1.5753e-03,\n",
       "                          7.2715e-02,  6.4814e-02],\n",
       "                        ...,\n",
       "                        [ 2.0299e-03,  7.9807e-02,  7.3138e-02,  ..., -8.6738e-02,\n",
       "                          7.2523e-02, -1.6820e-01],\n",
       "                        [-2.5255e-01, -1.7589e-01, -7.9536e-02,  ..., -6.1492e-03,\n",
       "                          3.7081e-02,  2.3215e-01],\n",
       "                        [ 2.9611e-01,  2.5593e-01,  1.3847e-01,  ...,  5.3602e-02,\n",
       "                         -9.7399e-02, -3.3035e-01]],\n",
       "               \n",
       "                       [[-5.6441e-01, -5.8755e-01, -4.2351e-01,  ..., -2.3773e-01,\n",
       "                         -1.6921e-01,  1.0488e-01],\n",
       "                        [ 1.6832e-01, -8.8455e-02, -3.6625e-02,  ...,  7.2082e-02,\n",
       "                          5.9914e-02, -1.1916e-01],\n",
       "                        [-6.1566e-02, -1.4037e-01, -7.0008e-02,  ..., -4.1916e-02,\n",
       "                         -7.2225e-02,  3.6245e-03],\n",
       "                        ...,\n",
       "                        [-1.4611e-01,  3.1406e-03,  1.1671e-03,  ..., -1.4617e-02,\n",
       "                         -9.9046e-03, -3.2444e-02],\n",
       "                        [ 2.0325e-02, -7.8089e-02, -7.6132e-02,  ...,  6.1193e-02,\n",
       "                         -1.1629e-02,  4.7078e-02],\n",
       "                        [-8.4670e-01, -5.5606e-01, -4.5877e-01,  ..., -2.0242e-01,\n",
       "                         -1.8378e-01, -1.2466e-01]],\n",
       "               \n",
       "                       [[ 3.1648e-01,  3.6867e-01,  2.1787e-01,  ...,  1.3791e-01,\n",
       "                         -3.0104e-02,  4.6563e-02],\n",
       "                        [-1.3270e-01, -5.2054e-02,  3.7175e-02,  ..., -1.3266e-01,\n",
       "                          1.4594e-02,  1.6438e-01],\n",
       "                        [-1.3614e-01, -4.8171e-02, -2.0684e-02,  ...,  7.2727e-02,\n",
       "                          1.1551e-05, -4.7665e-02],\n",
       "                        ...,\n",
       "                        [ 2.5066e-01,  2.9844e-01,  1.5939e-01,  ...,  1.1292e-01,\n",
       "                          5.8611e-02, -1.3523e-01],\n",
       "                        [-9.0387e-02, -2.5454e-01, -3.0616e-02,  ..., -1.7603e-01,\n",
       "                         -1.5102e-01, -3.0396e-01],\n",
       "                        [ 1.6686e-01,  2.0162e-01, -7.3480e-02,  ..., -8.6961e-02,\n",
       "                          1.0856e-01, -2.4373e-02]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 1.3764e-01,  2.2748e-02,  6.0448e-02,  ...,  1.0479e-01,\n",
       "                          7.2498e-02,  1.8839e-02],\n",
       "                        [-6.2199e-02, -1.6366e-02, -3.5039e-02,  ..., -1.8929e-01,\n",
       "                         -1.1146e-01, -3.5192e-01],\n",
       "                        [ 1.4242e-01,  1.0474e-01,  1.6330e-01,  ...,  1.4567e-01,\n",
       "                          1.5213e-02,  4.5412e-02],\n",
       "                        ...,\n",
       "                        [ 3.5795e-02,  6.6319e-02,  8.0527e-02,  ..., -2.5083e-02,\n",
       "                          9.4852e-02, -3.7748e-02],\n",
       "                        [ 6.3417e-01,  2.8169e-01,  2.2387e-01,  ...,  1.1364e-01,\n",
       "                          1.7798e-01,  2.9516e-01],\n",
       "                        [ 1.0026e-01, -3.0376e-02,  7.9024e-02,  ...,  3.4150e-02,\n",
       "                          7.1143e-02,  1.1901e-01]],\n",
       "               \n",
       "                       [[ 2.2077e-01,  1.5460e-01, -1.1305e-01,  ..., -1.6524e-03,\n",
       "                          8.4033e-02,  2.7288e-02],\n",
       "                        [-1.3661e-01, -5.2153e-02, -4.6046e-02,  ...,  6.7113e-02,\n",
       "                          2.4593e-02,  2.5498e-01],\n",
       "                        [ 1.4525e-01,  8.0613e-02,  8.9595e-03,  ...,  1.3923e-01,\n",
       "                          1.4344e-01,  6.0493e-02],\n",
       "                        ...,\n",
       "                        [ 2.5854e-01,  3.0554e-01,  1.5038e-01,  ...,  2.7621e-01,\n",
       "                          2.5346e-01,  1.4534e-01],\n",
       "                        [ 2.3685e-02,  1.0123e-01,  8.0752e-02,  ...,  7.9691e-02,\n",
       "                          4.7441e-02,  1.1785e-01],\n",
       "                        [-8.9002e-02,  1.1640e-01, -1.1943e-01,  ..., -2.3361e-02,\n",
       "                          6.6455e-02,  1.0693e-01]],\n",
       "               \n",
       "                       [[ 8.4074e-02,  7.4914e-02,  1.2311e-01,  ...,  1.7059e-02,\n",
       "                         -6.6188e-03,  5.6077e-02],\n",
       "                        [-2.2402e-01, -1.4918e-02, -1.5583e-01,  ...,  3.6930e-03,\n",
       "                          1.3028e-03,  9.9245e-02],\n",
       "                        [-6.5372e-01, -4.8669e-01, -5.7518e-01,  ..., -2.8279e-01,\n",
       "                         -3.9205e-01, -2.5514e-01],\n",
       "                        ...,\n",
       "                        [-3.1531e-02, -9.3009e-03, -4.2035e-02,  ..., -4.5000e-02,\n",
       "                          1.3255e-01,  1.3151e-01],\n",
       "                        [-4.8028e-01, -5.4939e-01, -3.7739e-01,  ..., -1.4338e-01,\n",
       "                         -2.5356e-01, -3.8501e-01],\n",
       "                        [ 5.2337e-02,  6.0852e-02, -5.7781e-03,  ...,  1.0125e-01,\n",
       "                          7.1011e-02, -5.6374e-02]]])),\n",
       "              ('encoder.cnn.1.0.0.bias',\n",
       "               tensor([ 0.0981, -0.0232, -0.1217, -0.0357, -0.0922,  0.0291,  0.0622, -0.0248,\n",
       "                        0.0005, -0.0409,  0.0868, -0.0122,  0.0074, -0.0225, -0.0055,  0.1526,\n",
       "                       -0.0702,  0.0743, -0.0942,  0.0286,  0.0854, -0.0355,  0.0018, -0.0875,\n",
       "                       -0.0203,  0.0011,  0.0211, -0.0929,  0.0284, -0.0598, -0.0602, -0.0261])),\n",
       "              ('encoder.cnn.1.0.1.weight',\n",
       "               tensor([1.0678, 1.0256, 0.7097, 0.9717, 1.0515, 0.9591, 0.7522, 0.8932, 0.7078,\n",
       "                       0.6288, 0.8160, 1.0724, 1.1221, 0.8570, 0.5680, 1.1297, 1.1404, 0.7157,\n",
       "                       0.6698, 0.8511, 1.0738, 0.6642, 0.5433, 0.7162, 0.8405, 0.7447, 1.2706,\n",
       "                       0.6916, 1.0462, 1.2006, 0.7401, 0.8544])),\n",
       "              ('encoder.cnn.1.0.1.bias',\n",
       "               tensor([-0.2999,  0.0737, -0.2629, -0.1118,  0.1555,  0.4789, -0.9365,  0.2331,\n",
       "                       -1.4148, -0.3185, -0.4012, -0.6412, -0.6366, -0.4411, -0.1595,  0.1722,\n",
       "                        0.0631,  0.0223, -0.6315, -0.3408, -0.1413, -0.3757, -0.2561, -0.9987,\n",
       "                       -0.6276, -0.2871, -0.3242, -0.4895, -0.1663, -0.4681, -0.9790,  0.2769])),\n",
       "              ('encoder.cnn.1.0.1.running_mean',\n",
       "               tensor([-0.4500, -3.6479, -0.1299, -1.3678, -1.3630, -2.7933,  3.3464, -3.1715,\n",
       "                        2.1133,  0.9467, -0.4467,  3.2718,  2.0374, -1.4011, -1.6137, -2.0470,\n",
       "                       -0.8504, -2.9652,  1.6224, -0.9057, -1.2521, -0.1034,  1.4349,  2.2679,\n",
       "                        0.9374, -1.4615,  0.1141,  0.8824, -0.0659,  3.3211,  1.7152, -4.2017])),\n",
       "              ('encoder.cnn.1.0.1.running_var',\n",
       "               tensor([ 1.3995, 22.5105, 13.1497,  5.6475,  2.1631,  4.4093,  5.8186,  2.4817,\n",
       "                        4.7889, 19.2847,  3.7796,  6.6411,  3.3421,  4.1660,  9.7208,  2.8600,\n",
       "                        4.1791,  5.2166,  3.0406,  3.1015,  2.5947,  7.8190, 20.8495,  3.0799,\n",
       "                        3.8260,  1.4516,  0.7706,  4.4275,  0.8636,  8.8401,  5.2656, 20.4875])),\n",
       "              ('encoder.cnn.1.0.1.num_batches_tracked', tensor(44082)),\n",
       "              ('encoder.cnn.2.0.0.weight',\n",
       "               tensor([[[-0.0085,  0.0744,  0.0140,  ..., -0.1263, -0.1427, -0.3413],\n",
       "                        [-0.1768, -0.0816,  0.0522,  ..., -0.1317, -0.1860, -0.2364],\n",
       "                        [ 0.0424,  0.1059,  0.0315,  ...,  0.0168,  0.1556,  0.1536],\n",
       "                        ...,\n",
       "                        [-0.0552,  0.0010, -0.0929,  ...,  0.0134,  0.0622, -0.0031],\n",
       "                        [ 0.1046,  0.0552, -0.0439,  ..., -0.0416,  0.0043, -0.1180],\n",
       "                        [ 0.0375, -0.1667, -0.1071,  ..., -0.1700, -0.0197,  0.0944]],\n",
       "               \n",
       "                       [[-0.0381, -0.0024,  0.0465,  ..., -0.1115, -0.1063, -0.4275],\n",
       "                        [-0.1991, -0.1007, -0.2018,  ..., -0.0245, -0.2531, -0.1756],\n",
       "                        [ 0.0393,  0.0705,  0.0491,  ...,  0.1104,  0.0378,  0.0679],\n",
       "                        ...,\n",
       "                        [-0.3799, -0.2437, -0.2741,  ..., -0.2843, -0.2323, -0.1848],\n",
       "                        [-0.0527, -0.0053, -0.0768,  ..., -0.0279,  0.0231, -0.0043],\n",
       "                        [ 0.0515,  0.0622,  0.2430,  ...,  0.2760,  0.2502,  0.1337]],\n",
       "               \n",
       "                       [[-0.1717,  0.0461,  0.0257,  ..., -0.0056,  0.1002, -0.5966],\n",
       "                        [-0.2204, -0.0975, -0.1481,  ..., -0.0047, -0.0227, -0.1098],\n",
       "                        [ 0.0015, -0.0967, -0.1450,  ..., -0.2236,  0.0123,  0.0188],\n",
       "                        ...,\n",
       "                        [-0.0829,  0.0387,  0.1143,  ...,  0.1998,  0.1503,  0.2724],\n",
       "                        [-0.1848, -0.2986, -0.2882,  ..., -0.0719, -0.2066, -0.1114],\n",
       "                        [ 0.1784,  0.0939,  0.0946,  ...,  0.1260, -0.0499,  0.0347]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0663, -0.0086,  0.1599,  ...,  0.2285,  0.3249,  0.5334],\n",
       "                        [ 0.0703, -0.0249,  0.0041,  ...,  0.0920, -0.0337,  0.1152],\n",
       "                        [ 0.4105,  0.3474,  0.1955,  ..., -0.0172, -0.1694, -0.2131],\n",
       "                        ...,\n",
       "                        [ 0.0724,  0.0438, -0.0012,  ...,  0.0889,  0.1276,  0.0474],\n",
       "                        [ 0.1806,  0.1404,  0.1645,  ..., -0.2234, -0.2294, -0.2515],\n",
       "                        [ 0.1471,  0.1732,  0.0341,  ..., -0.0539, -0.0474, -0.1822]],\n",
       "               \n",
       "                       [[ 0.1967,  0.2570,  0.2091,  ...,  0.1276,  0.2589,  0.0337],\n",
       "                        [-0.5047, -0.3105, -0.1734,  ...,  0.2187,  0.3031,  0.2934],\n",
       "                        [-0.0059, -0.1102, -0.0323,  ...,  0.0418,  0.0083, -0.0172],\n",
       "                        ...,\n",
       "                        [ 0.0698, -0.0931, -0.0523,  ...,  0.1471, -0.0129, -0.2023],\n",
       "                        [ 0.0188, -0.0182,  0.0898,  ...,  0.0877,  0.1269,  0.1269],\n",
       "                        [ 0.5213,  0.3313,  0.1827,  ..., -0.2146, -0.2736, -0.3993]],\n",
       "               \n",
       "                       [[-0.1352,  0.0327, -0.0688,  ..., -0.3985, -0.1667,  0.2920],\n",
       "                        [ 0.0990,  0.0184,  0.0072,  ...,  0.0515,  0.0371, -0.0452],\n",
       "                        [ 0.1831,  0.1592,  0.0572,  ...,  0.1289,  0.1315,  0.2143],\n",
       "                        ...,\n",
       "                        [ 0.0029,  0.0821,  0.0519,  ...,  0.1883,  0.1241,  0.1013],\n",
       "                        [-0.0121, -0.0993, -0.1235,  ...,  0.2072,  0.1706,  0.0504],\n",
       "                        [-0.1634, -0.1207, -0.0111,  ..., -0.0166, -0.0254, -0.0474]]])),\n",
       "              ('encoder.cnn.2.0.0.bias',\n",
       "               tensor([-0.0536, -0.0362,  0.0683, -0.0318, -0.0636, -0.0344, -0.0430, -0.0442,\n",
       "                       -0.0343, -0.0085,  0.0550, -0.0404, -0.0397, -0.0252, -0.0018,  0.0317,\n",
       "                       -0.0502,  0.0298,  0.0461,  0.0250, -0.0185,  0.0117, -0.0327,  0.0132,\n",
       "                        0.0317, -0.0578,  0.0604,  0.0227, -0.0556,  0.0389, -0.0611,  0.0221,\n",
       "                        0.0379, -0.0210, -0.0553,  0.0009, -0.0270,  0.0132,  0.0214,  0.0570,\n",
       "                       -0.0129, -0.0309,  0.0275, -0.0480, -0.0307,  0.0369, -0.0264,  0.0182,\n",
       "                        0.0343,  0.0008,  0.0278, -0.1336, -0.0330, -0.0390, -0.0530,  0.0213,\n",
       "                        0.0343, -0.0020, -0.0520,  0.0600,  0.0180, -0.0145, -0.0534, -0.0142])),\n",
       "              ('encoder.cnn.2.0.1.weight',\n",
       "               tensor([0.9593, 0.7192, 0.9892, 0.8373, 1.1083, 0.6374, 0.7919, 0.9184, 0.9980,\n",
       "                       0.8530, 0.7555, 0.6168, 0.8786, 0.9269, 0.7951, 0.8193, 0.8937, 0.9022,\n",
       "                       0.6605, 0.8115, 1.0291, 0.8083, 1.1786, 0.7419, 0.6987, 1.0648, 0.8093,\n",
       "                       0.7838, 0.7344, 1.0245, 0.7085, 1.0915, 1.1354, 0.6110, 0.8228, 0.8593,\n",
       "                       1.0940, 0.8428, 0.8452, 0.6750, 0.9001, 0.9220, 1.1035, 0.9358, 0.8173,\n",
       "                       1.1204, 0.7244, 0.7207, 0.9503, 0.9314, 0.9339, 1.3140, 0.8816, 0.8662,\n",
       "                       0.7123, 0.6502, 1.0819, 0.7072, 0.9190, 0.8410, 0.6009, 0.8235, 0.9797,\n",
       "                       0.8300])),\n",
       "              ('encoder.cnn.2.0.1.bias',\n",
       "               tensor([-0.7034, -0.3013, -0.2146, -0.1179, -0.4376, -0.4626, -0.1002, -0.1504,\n",
       "                       -0.8303, -0.4569, -0.3584, -0.2494, -0.1841, -0.2932, -0.3476, -0.5602,\n",
       "                       -0.0479, -0.4271, -0.3648, -0.1694, -0.1519, -0.1456, -1.0276, -0.5927,\n",
       "                       -0.6073, -0.4833, -0.7640, -0.2134, -0.2047, -0.4337, -0.5425, -1.0991,\n",
       "                        0.0302, -0.1071, -0.2842, -0.4533, -0.2489, -0.4727, -0.1725, -0.2994,\n",
       "                       -0.1616, -0.1843, -0.6099, -0.2095, -0.5078, -0.1136, -0.4275, -0.5149,\n",
       "                       -0.3854, -0.0600, -0.1601, -0.5778, -0.3966, -0.0882, -0.8294, -0.3140,\n",
       "                       -0.8188, -0.2477, -0.6878, -0.1649, -0.2619, -0.2348, -0.5878, -0.5616])),\n",
       "              ('encoder.cnn.2.0.1.running_mean',\n",
       "               tensor([-3.6071, -4.3316, -2.2260, -0.6762, -2.6710, -0.7210, -1.4847,  3.2529,\n",
       "                       -0.9363, -1.4030, -0.7099, -2.9287, -3.9667,  0.2526, -0.6072, -1.9930,\n",
       "                       -3.4621, -3.0442,  0.8274, -0.8005, -2.0946, -1.3511, -0.2887, -2.3894,\n",
       "                       -1.2769,  0.5438,  2.1197, -3.5327, -3.5430, -1.5044,  2.1850, -0.1476,\n",
       "                       -4.2542, -2.0784, -4.2088,  0.0064,  1.6965, -0.5745,  0.1889, -2.0529,\n",
       "                       -1.8177, -0.6156,  1.1562, -3.1088, -0.8790,  1.1681, -4.7238, -1.4836,\n",
       "                       -1.8155, -2.6686, -3.2991, -1.7402, -1.0079, -2.4058,  0.3237, -1.4212,\n",
       "                       -1.4807, -4.5370,  2.5863, -1.2840, -1.0989,  2.2541, -0.3931, -0.5787])),\n",
       "              ('encoder.cnn.2.0.1.running_var',\n",
       "               tensor([ 1.5192, 14.3272,  6.6911, 15.7467,  8.2739,  6.6087, 37.8227,  7.3784,\n",
       "                        1.5310,  3.6433,  5.4392, 11.5073, 21.8930,  4.4306,  5.6404,  3.8165,\n",
       "                       33.9856, 12.5900,  4.1821, 11.9402, 14.7755, 23.0713,  1.5311,  1.8072,\n",
       "                        3.3707,  3.3594,  3.7349, 10.8687, 14.7712,  3.4850, 10.5504,  2.2996,\n",
       "                       15.2878,  4.8251,  9.5947,  3.2586,  8.1507,  3.7275,  2.6100,  7.7057,\n",
       "                        9.2835,  6.3605,  9.8145,  9.5901,  1.4758, 10.9617,  6.7446,  3.3084,\n",
       "                        3.6585, 19.1548, 11.6217,  2.2902,  3.0095,  9.7415,  2.4253, 21.0049,\n",
       "                        3.5471, 10.3012,  5.3927, 25.5759,  4.9158, 10.8099,  4.2931,  2.9756])),\n",
       "              ('encoder.cnn.2.0.1.num_batches_tracked', tensor(44082)),\n",
       "              ('encoder.fc.1.weight',\n",
       "               tensor([[ 0.0264,  0.0048,  0.0265,  ...,  0.0256, -0.0275,  0.0674],\n",
       "                       [-0.0241, -0.0588, -0.0562,  ...,  0.0118,  0.0175,  0.0435],\n",
       "                       [-0.0376,  0.0209,  0.0265,  ..., -0.0068, -0.0829,  0.0760]])),\n",
       "              ('encoder.fc.1.bias', tensor([ 0.0656, -0.0955, -0.0875])),\n",
       "              ('decoder.model.1.weight',\n",
       "               tensor([[-0.2100, -0.3430,  0.5558],\n",
       "                       [ 0.5616,  0.3091, -0.1771],\n",
       "                       [ 0.1231, -0.4767, -0.1316],\n",
       "                       [ 0.0080,  0.1607,  0.6175],\n",
       "                       [-0.4116,  0.1732, -0.1995],\n",
       "                       [-0.0836,  0.5446,  0.2533],\n",
       "                       [ 0.6785, -0.1146, -0.0480],\n",
       "                       [ 0.3367, -0.1258, -0.1182],\n",
       "                       [-0.4372,  0.1881,  0.1575],\n",
       "                       [ 0.0556, -0.1520, -0.4962],\n",
       "                       [ 0.0670,  0.1459, -0.1901],\n",
       "                       [-0.4752,  0.2986,  0.0240],\n",
       "                       [-0.0591, -0.4497, -0.4741],\n",
       "                       [-0.4278, -0.5987, -0.0849],\n",
       "                       [ 0.1060, -0.3013,  0.0144],\n",
       "                       [ 0.5334,  0.4297,  0.1809]])),\n",
       "              ('decoder.model.1.bias',\n",
       "               tensor([-0.3510, -0.2057,  0.1908, -0.4843,  0.1237, -0.1249, -0.2031, -0.4328,\n",
       "                        0.2295,  0.4248,  0.1053,  0.1116, -0.2255,  0.0041,  0.0827,  0.1337])),\n",
       "              ('decoder.model.3.weight',\n",
       "               tensor([[ 0.1324, -0.0964,  0.1100,  ...,  0.2546, -0.1328, -0.0831],\n",
       "                       [ 0.0854,  0.3180, -0.2431,  ...,  0.0490, -0.0200,  0.0007],\n",
       "                       [ 0.1090,  0.1545, -0.2477,  ..., -0.4568, -0.2201, -0.1730],\n",
       "                       ...,\n",
       "                       [-0.1398, -0.3974, -0.0408,  ..., -0.0607,  0.1387, -0.0197],\n",
       "                       [-0.0642,  0.0801, -0.2903,  ..., -0.0874,  0.1607, -0.2391],\n",
       "                       [ 0.0462, -0.3545,  0.0407,  ...,  0.0036,  0.2833, -0.0879]])),\n",
       "              ('decoder.model.3.bias',\n",
       "               tensor([-0.1579,  0.0441,  0.0350,  0.1218, -0.1289, -0.1343,  0.0806, -0.0742,\n",
       "                       -0.0383, -0.1137, -0.1289,  0.2025, -0.0830,  0.1144,  0.1346,  0.0035,\n",
       "                        0.0039,  0.0705,  0.1214, -0.1477,  0.1098, -0.0580,  0.0757, -0.0741,\n",
       "                       -0.1435, -0.0270, -0.0468, -0.1715, -0.0927, -0.0560, -0.1208,  0.1468,\n",
       "                        0.0786, -0.0504,  0.2239, -0.1045, -0.1477, -0.1119, -0.1876, -0.1459,\n",
       "                       -0.2228, -0.2216,  0.0328,  0.0788,  0.1781,  0.0660, -0.0415,  0.0073,\n",
       "                       -0.0741,  0.0196, -0.2397,  0.0923,  0.0132,  0.0178,  0.0430, -0.0021,\n",
       "                        0.0905,  0.0298,  0.0502,  0.0606,  0.1644,  0.1560,  0.0829,  0.1911])),\n",
       "              ('decoder.model.5.weight',\n",
       "               tensor([[ 3.4373e-03,  3.7015e-03,  3.2010e-02,  ..., -2.9372e-01,\n",
       "                        -1.0402e-01, -1.3729e+00],\n",
       "                       [-2.5603e-01,  3.6295e-01, -5.4782e-01,  ..., -5.8125e-02,\n",
       "                         8.5134e-02,  1.0631e-01],\n",
       "                       [-9.6707e-02,  1.7238e-02, -1.1205e-01,  ...,  2.6772e-03,\n",
       "                         8.9055e-02,  7.8631e-02],\n",
       "                       ...,\n",
       "                       [ 8.7055e-02,  9.3563e-02,  2.2055e-02,  ..., -1.0473e-02,\n",
       "                         3.9673e-02,  4.1766e-02],\n",
       "                       [ 8.2596e-02, -1.7338e-02, -8.1839e-02,  ..., -7.8264e-02,\n",
       "                         3.2934e-02, -7.1127e-02],\n",
       "                       [-1.9372e-01,  1.3545e-03,  1.5866e-01,  ...,  9.8124e-02,\n",
       "                        -3.3597e-01,  1.8872e-01]])),\n",
       "              ('decoder.model.5.bias',\n",
       "               tensor([ 4.3190e-03, -3.3449e-02, -1.1993e-01,  2.3358e-03, -1.2266e-01,\n",
       "                        9.7033e-02, -1.1726e-01,  5.4473e-02,  9.1598e-02, -1.0100e-01,\n",
       "                        1.2725e-01,  1.1473e-01,  9.0815e-02,  1.4697e-01, -1.0984e-02,\n",
       "                        1.1090e-02,  8.1528e-02,  6.1083e-02, -1.7412e-02,  1.7425e-01,\n",
       "                        4.8909e-02, -3.3776e-02, -5.4407e-03,  1.0838e-01, -3.5780e-02,\n",
       "                       -1.7145e-02, -2.8703e-03, -3.7443e-02, -7.2179e-03, -2.8070e-04,\n",
       "                       -1.0255e-01, -3.1009e-02,  6.3284e-02,  5.1745e-03,  8.7120e-02,\n",
       "                       -1.1375e-01, -2.6699e-05,  5.9149e-02,  2.5641e-02,  9.9608e-02,\n",
       "                        8.7714e-02, -3.1831e-02,  4.9858e-02, -5.9144e-02,  8.2312e-02,\n",
       "                        1.6558e-01, -1.0823e-01,  7.7739e-02,  1.5046e-02, -1.1304e-01,\n",
       "                       -6.9485e-02, -4.7261e-02,  6.4221e-02,  6.2712e-03, -3.2501e-02,\n",
       "                       -9.4969e-02, -7.8733e-02, -5.8348e-02,  1.0864e-01, -1.0852e-01,\n",
       "                       -1.3434e-01, -7.8496e-02,  2.5269e-02,  2.5774e-02,  5.7567e-02,\n",
       "                        1.3716e-01,  2.1969e-02,  1.2753e-02,  4.7802e-02, -6.3904e-02,\n",
       "                        5.7206e-02, -1.1675e-01, -7.8070e-02, -2.3975e-02, -8.0029e-02,\n",
       "                       -5.8307e-02, -1.1334e-02, -1.4545e-02, -7.1893e-02, -9.5878e-02,\n",
       "                       -1.1710e-01, -7.6790e-02, -1.1632e-01, -1.3062e-01,  1.0417e-01,\n",
       "                        4.1025e-02,  3.3616e-02,  1.1188e-01,  2.0946e-02, -1.8946e-02,\n",
       "                       -2.6717e-02, -5.1380e-02,  3.5058e-02, -6.6735e-03, -1.0499e-01,\n",
       "                        4.5625e-02, -1.0332e-01,  7.1484e-02, -5.1544e-03, -4.6359e-02,\n",
       "                        3.3008e-02,  5.5703e-02,  1.2441e-01,  1.2450e-02, -8.7544e-02,\n",
       "                       -5.2787e-02, -2.2308e-02, -1.8207e-02, -6.8505e-02, -1.0082e-01,\n",
       "                        1.6529e-01, -1.1829e-01,  7.6016e-02, -1.7439e-02, -5.0338e-02,\n",
       "                       -6.1043e-02,  8.7973e-02,  7.8572e-03,  7.2192e-02,  8.6594e-02,\n",
       "                       -6.2971e-02,  4.0718e-02,  5.7386e-02, -4.0043e-02, -9.7851e-02,\n",
       "                        1.0156e-01, -1.1612e-01, -1.2147e-01, -6.4187e-02,  3.3333e-02,\n",
       "                        1.0407e-01, -9.7582e-02, -4.2196e-02,  1.0498e-01,  1.4749e-01,\n",
       "                       -1.2481e-02, -1.0583e-01,  7.8218e-02, -3.2539e-02, -9.6076e-02,\n",
       "                        6.0741e-02, -1.2313e-01,  7.6492e-02, -9.0187e-02,  7.3966e-02,\n",
       "                        2.3417e-02, -5.8750e-02,  1.2623e-01,  1.3285e-01, -2.7072e-02,\n",
       "                        5.2865e-02, -2.2424e-02, -2.9260e-02, -6.7608e-02, -1.1999e-01,\n",
       "                        1.2232e-01,  1.5556e-02, -1.0469e-01, -1.3101e-01,  5.4486e-02,\n",
       "                       -4.0871e-02, -9.2857e-02,  8.9341e-03, -9.1784e-02,  6.5829e-02,\n",
       "                       -5.1674e-02,  3.8492e-02, -7.3262e-02, -8.4263e-03, -5.8205e-02,\n",
       "                       -2.5477e-02,  1.2416e-02,  7.9579e-02, -5.1230e-02, -4.6857e-02,\n",
       "                       -1.0109e-01, -1.0776e-01, -8.4913e-02, -7.7664e-02,  1.5829e-01,\n",
       "                       -1.2183e-01,  1.1028e-01,  6.9219e-02,  3.7394e-02,  8.1393e-02,\n",
       "                        1.4106e-01,  1.6534e-01,  8.1609e-02, -4.2029e-02,  3.5067e-02,\n",
       "                       -4.3102e-02, -9.9493e-02,  4.0093e-02,  1.6222e-01,  1.1184e-01,\n",
       "                       -8.5796e-02, -2.6266e-02,  6.9312e-02,  1.2292e-01, -2.1991e-01,\n",
       "                        3.9323e-02,  4.2937e-02,  8.7238e-02, -1.9247e-02, -2.5925e-02,\n",
       "                       -6.5308e-02,  1.0042e-01, -4.1858e-02, -1.2060e-02,  1.5491e-01,\n",
       "                       -1.1048e-01, -4.1861e-03, -1.3267e-01,  4.2791e-02, -2.2433e-02,\n",
       "                        2.8031e-03,  4.6927e-02, -6.8601e-02,  2.4055e-02, -6.5974e-02,\n",
       "                        7.5998e-02,  5.0571e-02,  6.2949e-02, -2.4768e-02,  5.1479e-02,\n",
       "                       -1.0013e-01,  2.9039e-02,  5.4705e-02, -1.1557e-01,  1.1703e-01,\n",
       "                        2.0277e-03, -7.8625e-02, -8.1534e-02,  2.4879e-02, -8.2944e-03,\n",
       "                        9.5637e-02,  4.3854e-02,  1.5648e-01, -8.6056e-02, -7.0079e-02,\n",
       "                        2.3783e-02, -8.2289e-02, -6.2911e-02, -7.1726e-02,  1.2607e-01,\n",
       "                        8.4428e-02, -1.4850e-01, -1.1757e-03,  1.1618e-01,  1.0956e-01,\n",
       "                        1.7408e-01,  1.6535e-02,  2.9401e-02,  1.3479e-01,  7.0612e-02,\n",
       "                        3.8594e-02])),\n",
       "              ('decoder.model.7.weight',\n",
       "               tensor([[ 0.4077,  0.1855,  0.0551,  ..., -0.0215,  0.0363, -0.2137],\n",
       "                       [ 0.2508,  0.1587, -0.0502,  ...,  0.0712,  0.0347,  0.0907],\n",
       "                       [-0.0183,  0.1504,  0.0116,  ...,  0.0346,  0.0372,  0.3515],\n",
       "                       ...,\n",
       "                       [ 0.1600,  0.0759,  0.0117,  ..., -0.0082,  0.0821,  0.1562],\n",
       "                       [ 0.1541,  0.0472,  0.0251,  ..., -0.0288,  0.0950,  0.1623],\n",
       "                       [ 0.0988,  0.0763, -0.0105,  ...,  0.0075,  0.0994,  0.1357]])),\n",
       "              ('decoder.model.7.bias',\n",
       "               tensor([0.2041, 0.0902, 0.0366, 0.0168, 0.0358, 0.0443, 0.0379, 0.0495, 0.0632,\n",
       "                       0.1072, 0.0882, 0.0550, 0.0771, 0.0867, 0.0682, 0.0503, 0.1001, 0.0970,\n",
       "                       0.0576, 0.0697, 0.1188, 0.0758, 0.1295, 0.0706, 0.0869, 0.0973, 0.0967,\n",
       "                       0.1271, 0.0915, 0.0370, 0.0554, 0.0668, 0.1219, 0.1717, 0.1815, 0.1652,\n",
       "                       0.1630, 0.1421, 0.1034, 0.1667, 0.1525, 0.1260, 0.1546, 0.1549, 0.1313,\n",
       "                       0.1056, 0.1532, 0.1760, 0.1402, 0.1017, 0.1464, 0.1175, 0.1809, 0.1534,\n",
       "                       0.1864, 0.1838, 0.1457, 0.1548, 0.1569, 0.1802, 0.1786, 0.2112, 0.1825,\n",
       "                       0.1471, 0.1571, 0.1804, 0.1703, 0.2043, 0.1678, 0.1650, 0.1486, 0.1891,\n",
       "                       0.1834, 0.1313, 0.1718, 0.1763, 0.2062, 0.1955, 0.2031, 0.1832, 0.1900,\n",
       "                       0.1732, 0.1804, 0.1779, 0.1460, 0.2085, 0.1899, 0.1905, 0.1489, 0.1597,\n",
       "                       0.1459, 0.1632, 0.1203, 0.1757, 0.1817, 0.1638, 0.1476, 0.1963, 0.1762,\n",
       "                       0.2099, 0.1724, 0.2021, 0.1378, 0.1317, 0.1549, 0.1265, 0.1904, 0.1640,\n",
       "                       0.1492, 0.1963, 0.1394, 0.1811, 0.1739, 0.1977, 0.1682, 0.1830, 0.1840,\n",
       "                       0.1389, 0.1989, 0.2050, 0.1832, 0.1585, 0.1732, 0.1733, 0.1688, 0.1663,\n",
       "                       0.1480, 0.1970, 0.1701, 0.1258, 0.1558, 0.1803, 0.1538, 0.1979, 0.1488,\n",
       "                       0.1759, 0.1714, 0.1583, 0.1867, 0.1512, 0.1376, 0.1893, 0.1503, 0.1827,\n",
       "                       0.1544, 0.1697, 0.1729, 0.1570, 0.1560, 0.1428, 0.1959, 0.1261, 0.1520,\n",
       "                       0.1948, 0.1802, 0.1678, 0.1801, 0.1206, 0.1744, 0.1625, 0.1169, 0.1387,\n",
       "                       0.1697, 0.1725, 0.1633, 0.1649, 0.1277, 0.1882, 0.1124, 0.1262, 0.1740,\n",
       "                       0.1533, 0.1237, 0.1384, 0.1252, 0.1514, 0.1373, 0.1713, 0.1271, 0.1287,\n",
       "                       0.1414, 0.1427, 0.1669, 0.1257, 0.1198, 0.1296, 0.1825, 0.1736, 0.1683,\n",
       "                       0.1479, 0.1450, 0.1205, 0.1143, 0.1415, 0.1815, 0.1741, 0.1143, 0.1409,\n",
       "                       0.1383, 0.1436, 0.1677, 0.1399, 0.1760, 0.1403, 0.1417, 0.1102, 0.1233,\n",
       "                       0.1466, 0.1359, 0.1228, 0.1665, 0.1165, 0.1536, 0.1215, 0.0986, 0.1187,\n",
       "                       0.1220, 0.1275, 0.1520, 0.1097, 0.0907, 0.1393, 0.1157, 0.0999, 0.1644,\n",
       "                       0.1239, 0.1596, 0.1086, 0.1531, 0.1584, 0.1506, 0.1080, 0.1685, 0.0967,\n",
       "                       0.1264, 0.1020, 0.1370, 0.0904, 0.1628, 0.1449, 0.1473, 0.1335, 0.1207,\n",
       "                       0.1187, 0.1115, 0.1509, 0.0985, 0.1078, 0.1024, 0.1082, 0.1127, 0.1104,\n",
       "                       0.1174, 0.1304, 0.1289, 0.0976, 0.1440, 0.0886, 0.1060, 0.0832, 0.0872,\n",
       "                       0.1019, 0.1064, 0.1038, 0.0891, 0.0916, 0.1319, 0.1102, 0.1007, 0.1423,\n",
       "                       0.1142, 0.1552, 0.1278, 0.1380, 0.1143, 0.1184, 0.1075, 0.0810, 0.1152,\n",
       "                       0.1440, 0.1328, 0.1111, 0.1389, 0.0966, 0.1546, 0.1074, 0.0857, 0.1445,\n",
       "                       0.1157, 0.0905, 0.0851, 0.0893, 0.0891, 0.1307, 0.1150, 0.1082, 0.0942,\n",
       "                       0.0753, 0.1164, 0.1185, 0.1184, 0.0797, 0.1072, 0.1334, 0.1418, 0.1100,\n",
       "                       0.0910, 0.1184, 0.1063, 0.0830, 0.0966, 0.1173, 0.0979, 0.0865, 0.1111,\n",
       "                       0.1023, 0.1177, 0.0765, 0.1243, 0.1337, 0.0964, 0.1061, 0.1098, 0.0889,\n",
       "                       0.1277, 0.0752, 0.0822, 0.1360, 0.1288, 0.0856, 0.0753, 0.1092, 0.0747,\n",
       "                       0.1471, 0.1190, 0.0973, 0.1138, 0.1575, 0.1260, 0.1512, 0.1799, 0.1195,\n",
       "                       0.1820])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.0.weight',\n",
       "               tensor([[[-0.2702, -0.5835, -0.2809, -0.2388, -0.2410]],\n",
       "               \n",
       "                       [[ 0.1957,  0.2095, -0.1171,  0.0027, -0.3216]],\n",
       "               \n",
       "                       [[-0.1548,  0.4688,  0.3817, -0.3931, -0.1283]],\n",
       "               \n",
       "                       [[-0.4041,  0.3574, -0.3008,  0.1009, -0.1252]],\n",
       "               \n",
       "                       [[-0.5530,  0.3542,  0.4249, -0.3230, -0.2633]],\n",
       "               \n",
       "                       [[-0.1498, -0.3973,  0.0577,  0.4716, -0.1178]],\n",
       "               \n",
       "                       [[-0.3342, -0.0057, -0.1332, -0.2695, -0.5383]],\n",
       "               \n",
       "                       [[ 0.4483, -0.2075, -0.2363, -0.2981,  0.3196]],\n",
       "               \n",
       "                       [[ 0.1340, -0.2998,  0.4229, -0.3330,  0.1517]],\n",
       "               \n",
       "                       [[-0.3221, -0.3529, -0.1921, -0.4498, -0.0400]],\n",
       "               \n",
       "                       [[ 0.4506,  0.5530,  0.3369,  0.1712, -0.0774]],\n",
       "               \n",
       "                       [[-0.3510,  0.2604, -0.0499, -0.2186,  0.3642]],\n",
       "               \n",
       "                       [[-0.3944,  0.1938, -0.4185, -0.0981, -0.1930]],\n",
       "               \n",
       "                       [[-0.3920,  0.0249, -0.1904,  0.1422, -0.1057]],\n",
       "               \n",
       "                       [[ 0.1744,  0.3259, -0.0861, -0.3786,  0.6779]],\n",
       "               \n",
       "                       [[-0.4510, -0.0430,  0.0474,  0.2054, -0.1969]]])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.0.bias',\n",
       "               tensor([ 0.4592, -0.2009,  0.0247,  0.1589,  0.2229, -0.0890,  0.3721,  0.2018,\n",
       "                        0.5668,  0.1027, -0.0395,  0.2214,  0.0700, -0.3394,  0.3707, -0.3069])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.1.weight',\n",
       "               tensor([0.8557, 0.8183, 0.6639, 0.7765, 0.9407, 0.5031, 0.8668, 0.6651, 1.3258,\n",
       "                       0.6958, 0.9750, 1.0119, 0.9012, 0.8772, 1.3174, 0.5979])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.1.bias',\n",
       "               tensor([ 0.0074,  0.0758,  0.3050, -0.1588,  0.4276, -0.2509,  0.0278,  0.2762,\n",
       "                       -0.4893, -0.6007,  0.1819,  0.2978, -0.3047, -0.3658, -0.0686,  0.1659])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.1.running_mean',\n",
       "               tensor([-0.6133, -0.2228,  0.1381, -0.0899, -0.0150, -0.1830, -0.4798,  0.2178,\n",
       "                        0.6185, -0.8007,  0.9122,  0.2298, -0.5346, -0.6904,  0.8512, -0.6004])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.1.running_var',\n",
       "               tensor([0.1332, 0.0011, 0.0035, 0.0072, 0.0084, 0.0026, 0.0834, 0.0018, 0.0003,\n",
       "                       0.0942, 0.1072, 0.0004, 0.0418, 0.0144, 0.0267, 0.0108])),\n",
       "              ('variational_encoder.encoder.cnn.0.0.1.num_batches_tracked',\n",
       "               tensor(44082)),\n",
       "              ('variational_encoder.encoder.cnn.1.0.0.weight',\n",
       "               tensor([[[ 2.6956e-01,  1.3200e-01,  1.4546e-01,  ...,  1.2638e-02,\n",
       "                         -1.8367e-01, -2.4225e-01],\n",
       "                        [-1.2385e-01, -3.9293e-02,  1.2478e-01,  ..., -1.0693e-01,\n",
       "                         -4.7730e-02, -1.8425e-01],\n",
       "                        [-7.8778e-02, -1.6643e-01, -1.4380e-01,  ..., -1.5753e-03,\n",
       "                          7.2715e-02,  6.4814e-02],\n",
       "                        ...,\n",
       "                        [ 2.0299e-03,  7.9807e-02,  7.3138e-02,  ..., -8.6738e-02,\n",
       "                          7.2523e-02, -1.6820e-01],\n",
       "                        [-2.5255e-01, -1.7589e-01, -7.9536e-02,  ..., -6.1492e-03,\n",
       "                          3.7081e-02,  2.3215e-01],\n",
       "                        [ 2.9611e-01,  2.5593e-01,  1.3847e-01,  ...,  5.3602e-02,\n",
       "                         -9.7399e-02, -3.3035e-01]],\n",
       "               \n",
       "                       [[-5.6441e-01, -5.8755e-01, -4.2351e-01,  ..., -2.3773e-01,\n",
       "                         -1.6921e-01,  1.0488e-01],\n",
       "                        [ 1.6832e-01, -8.8455e-02, -3.6625e-02,  ...,  7.2082e-02,\n",
       "                          5.9914e-02, -1.1916e-01],\n",
       "                        [-6.1566e-02, -1.4037e-01, -7.0008e-02,  ..., -4.1916e-02,\n",
       "                         -7.2225e-02,  3.6245e-03],\n",
       "                        ...,\n",
       "                        [-1.4611e-01,  3.1406e-03,  1.1671e-03,  ..., -1.4617e-02,\n",
       "                         -9.9046e-03, -3.2444e-02],\n",
       "                        [ 2.0325e-02, -7.8089e-02, -7.6132e-02,  ...,  6.1193e-02,\n",
       "                         -1.1629e-02,  4.7078e-02],\n",
       "                        [-8.4670e-01, -5.5606e-01, -4.5877e-01,  ..., -2.0242e-01,\n",
       "                         -1.8378e-01, -1.2466e-01]],\n",
       "               \n",
       "                       [[ 3.1648e-01,  3.6867e-01,  2.1787e-01,  ...,  1.3791e-01,\n",
       "                         -3.0104e-02,  4.6563e-02],\n",
       "                        [-1.3270e-01, -5.2054e-02,  3.7175e-02,  ..., -1.3266e-01,\n",
       "                          1.4594e-02,  1.6438e-01],\n",
       "                        [-1.3614e-01, -4.8171e-02, -2.0684e-02,  ...,  7.2727e-02,\n",
       "                          1.1551e-05, -4.7665e-02],\n",
       "                        ...,\n",
       "                        [ 2.5066e-01,  2.9844e-01,  1.5939e-01,  ...,  1.1292e-01,\n",
       "                          5.8611e-02, -1.3523e-01],\n",
       "                        [-9.0387e-02, -2.5454e-01, -3.0616e-02,  ..., -1.7603e-01,\n",
       "                         -1.5102e-01, -3.0396e-01],\n",
       "                        [ 1.6686e-01,  2.0162e-01, -7.3480e-02,  ..., -8.6961e-02,\n",
       "                          1.0856e-01, -2.4373e-02]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 1.3764e-01,  2.2748e-02,  6.0448e-02,  ...,  1.0479e-01,\n",
       "                          7.2498e-02,  1.8839e-02],\n",
       "                        [-6.2199e-02, -1.6366e-02, -3.5039e-02,  ..., -1.8929e-01,\n",
       "                         -1.1146e-01, -3.5192e-01],\n",
       "                        [ 1.4242e-01,  1.0474e-01,  1.6330e-01,  ...,  1.4567e-01,\n",
       "                          1.5213e-02,  4.5412e-02],\n",
       "                        ...,\n",
       "                        [ 3.5795e-02,  6.6319e-02,  8.0527e-02,  ..., -2.5083e-02,\n",
       "                          9.4852e-02, -3.7748e-02],\n",
       "                        [ 6.3417e-01,  2.8169e-01,  2.2387e-01,  ...,  1.1364e-01,\n",
       "                          1.7798e-01,  2.9516e-01],\n",
       "                        [ 1.0026e-01, -3.0376e-02,  7.9024e-02,  ...,  3.4150e-02,\n",
       "                          7.1143e-02,  1.1901e-01]],\n",
       "               \n",
       "                       [[ 2.2077e-01,  1.5460e-01, -1.1305e-01,  ..., -1.6524e-03,\n",
       "                          8.4033e-02,  2.7288e-02],\n",
       "                        [-1.3661e-01, -5.2153e-02, -4.6046e-02,  ...,  6.7113e-02,\n",
       "                          2.4593e-02,  2.5498e-01],\n",
       "                        [ 1.4525e-01,  8.0613e-02,  8.9595e-03,  ...,  1.3923e-01,\n",
       "                          1.4344e-01,  6.0493e-02],\n",
       "                        ...,\n",
       "                        [ 2.5854e-01,  3.0554e-01,  1.5038e-01,  ...,  2.7621e-01,\n",
       "                          2.5346e-01,  1.4534e-01],\n",
       "                        [ 2.3685e-02,  1.0123e-01,  8.0752e-02,  ...,  7.9691e-02,\n",
       "                          4.7441e-02,  1.1785e-01],\n",
       "                        [-8.9002e-02,  1.1640e-01, -1.1943e-01,  ..., -2.3361e-02,\n",
       "                          6.6455e-02,  1.0693e-01]],\n",
       "               \n",
       "                       [[ 8.4074e-02,  7.4914e-02,  1.2311e-01,  ...,  1.7059e-02,\n",
       "                         -6.6188e-03,  5.6077e-02],\n",
       "                        [-2.2402e-01, -1.4918e-02, -1.5583e-01,  ...,  3.6930e-03,\n",
       "                          1.3028e-03,  9.9245e-02],\n",
       "                        [-6.5372e-01, -4.8669e-01, -5.7518e-01,  ..., -2.8279e-01,\n",
       "                         -3.9205e-01, -2.5514e-01],\n",
       "                        ...,\n",
       "                        [-3.1531e-02, -9.3009e-03, -4.2035e-02,  ..., -4.5000e-02,\n",
       "                          1.3255e-01,  1.3151e-01],\n",
       "                        [-4.8028e-01, -5.4939e-01, -3.7739e-01,  ..., -1.4338e-01,\n",
       "                         -2.5356e-01, -3.8501e-01],\n",
       "                        [ 5.2337e-02,  6.0852e-02, -5.7781e-03,  ...,  1.0125e-01,\n",
       "                          7.1011e-02, -5.6374e-02]]])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.0.bias',\n",
       "               tensor([ 0.0981, -0.0232, -0.1217, -0.0357, -0.0922,  0.0291,  0.0622, -0.0248,\n",
       "                        0.0005, -0.0409,  0.0868, -0.0122,  0.0074, -0.0225, -0.0055,  0.1526,\n",
       "                       -0.0702,  0.0743, -0.0942,  0.0286,  0.0854, -0.0355,  0.0018, -0.0875,\n",
       "                       -0.0203,  0.0011,  0.0211, -0.0929,  0.0284, -0.0598, -0.0602, -0.0261])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.1.weight',\n",
       "               tensor([1.0678, 1.0256, 0.7097, 0.9717, 1.0515, 0.9591, 0.7522, 0.8932, 0.7078,\n",
       "                       0.6288, 0.8160, 1.0724, 1.1221, 0.8570, 0.5680, 1.1297, 1.1404, 0.7157,\n",
       "                       0.6698, 0.8511, 1.0738, 0.6642, 0.5433, 0.7162, 0.8405, 0.7447, 1.2706,\n",
       "                       0.6916, 1.0462, 1.2006, 0.7401, 0.8544])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.1.bias',\n",
       "               tensor([-0.2999,  0.0737, -0.2629, -0.1118,  0.1555,  0.4789, -0.9365,  0.2331,\n",
       "                       -1.4148, -0.3185, -0.4012, -0.6412, -0.6366, -0.4411, -0.1595,  0.1722,\n",
       "                        0.0631,  0.0223, -0.6315, -0.3408, -0.1413, -0.3757, -0.2561, -0.9987,\n",
       "                       -0.6276, -0.2871, -0.3242, -0.4895, -0.1663, -0.4681, -0.9790,  0.2769])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.1.running_mean',\n",
       "               tensor([-0.4500, -3.6479, -0.1299, -1.3678, -1.3630, -2.7933,  3.3464, -3.1715,\n",
       "                        2.1133,  0.9467, -0.4467,  3.2718,  2.0374, -1.4011, -1.6137, -2.0470,\n",
       "                       -0.8504, -2.9652,  1.6224, -0.9057, -1.2521, -0.1034,  1.4349,  2.2679,\n",
       "                        0.9374, -1.4615,  0.1141,  0.8824, -0.0659,  3.3211,  1.7152, -4.2017])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.1.running_var',\n",
       "               tensor([ 1.3995, 22.5105, 13.1497,  5.6475,  2.1631,  4.4093,  5.8186,  2.4817,\n",
       "                        4.7889, 19.2847,  3.7796,  6.6411,  3.3421,  4.1660,  9.7208,  2.8600,\n",
       "                        4.1791,  5.2166,  3.0406,  3.1015,  2.5947,  7.8190, 20.8495,  3.0799,\n",
       "                        3.8260,  1.4516,  0.7706,  4.4275,  0.8636,  8.8401,  5.2656, 20.4875])),\n",
       "              ('variational_encoder.encoder.cnn.1.0.1.num_batches_tracked',\n",
       "               tensor(44082)),\n",
       "              ('variational_encoder.encoder.cnn.2.0.0.weight',\n",
       "               tensor([[[-0.0085,  0.0744,  0.0140,  ..., -0.1263, -0.1427, -0.3413],\n",
       "                        [-0.1768, -0.0816,  0.0522,  ..., -0.1317, -0.1860, -0.2364],\n",
       "                        [ 0.0424,  0.1059,  0.0315,  ...,  0.0168,  0.1556,  0.1536],\n",
       "                        ...,\n",
       "                        [-0.0552,  0.0010, -0.0929,  ...,  0.0134,  0.0622, -0.0031],\n",
       "                        [ 0.1046,  0.0552, -0.0439,  ..., -0.0416,  0.0043, -0.1180],\n",
       "                        [ 0.0375, -0.1667, -0.1071,  ..., -0.1700, -0.0197,  0.0944]],\n",
       "               \n",
       "                       [[-0.0381, -0.0024,  0.0465,  ..., -0.1115, -0.1063, -0.4275],\n",
       "                        [-0.1991, -0.1007, -0.2018,  ..., -0.0245, -0.2531, -0.1756],\n",
       "                        [ 0.0393,  0.0705,  0.0491,  ...,  0.1104,  0.0378,  0.0679],\n",
       "                        ...,\n",
       "                        [-0.3799, -0.2437, -0.2741,  ..., -0.2843, -0.2323, -0.1848],\n",
       "                        [-0.0527, -0.0053, -0.0768,  ..., -0.0279,  0.0231, -0.0043],\n",
       "                        [ 0.0515,  0.0622,  0.2430,  ...,  0.2760,  0.2502,  0.1337]],\n",
       "               \n",
       "                       [[-0.1717,  0.0461,  0.0257,  ..., -0.0056,  0.1002, -0.5966],\n",
       "                        [-0.2204, -0.0975, -0.1481,  ..., -0.0047, -0.0227, -0.1098],\n",
       "                        [ 0.0015, -0.0967, -0.1450,  ..., -0.2236,  0.0123,  0.0188],\n",
       "                        ...,\n",
       "                        [-0.0829,  0.0387,  0.1143,  ...,  0.1998,  0.1503,  0.2724],\n",
       "                        [-0.1848, -0.2986, -0.2882,  ..., -0.0719, -0.2066, -0.1114],\n",
       "                        [ 0.1784,  0.0939,  0.0946,  ...,  0.1260, -0.0499,  0.0347]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0663, -0.0086,  0.1599,  ...,  0.2285,  0.3249,  0.5334],\n",
       "                        [ 0.0703, -0.0249,  0.0041,  ...,  0.0920, -0.0337,  0.1152],\n",
       "                        [ 0.4105,  0.3474,  0.1955,  ..., -0.0172, -0.1694, -0.2131],\n",
       "                        ...,\n",
       "                        [ 0.0724,  0.0438, -0.0012,  ...,  0.0889,  0.1276,  0.0474],\n",
       "                        [ 0.1806,  0.1404,  0.1645,  ..., -0.2234, -0.2294, -0.2515],\n",
       "                        [ 0.1471,  0.1732,  0.0341,  ..., -0.0539, -0.0474, -0.1822]],\n",
       "               \n",
       "                       [[ 0.1967,  0.2570,  0.2091,  ...,  0.1276,  0.2589,  0.0337],\n",
       "                        [-0.5047, -0.3105, -0.1734,  ...,  0.2187,  0.3031,  0.2934],\n",
       "                        [-0.0059, -0.1102, -0.0323,  ...,  0.0418,  0.0083, -0.0172],\n",
       "                        ...,\n",
       "                        [ 0.0698, -0.0931, -0.0523,  ...,  0.1471, -0.0129, -0.2023],\n",
       "                        [ 0.0188, -0.0182,  0.0898,  ...,  0.0877,  0.1269,  0.1269],\n",
       "                        [ 0.5213,  0.3313,  0.1827,  ..., -0.2146, -0.2736, -0.3993]],\n",
       "               \n",
       "                       [[-0.1352,  0.0327, -0.0688,  ..., -0.3985, -0.1667,  0.2920],\n",
       "                        [ 0.0990,  0.0184,  0.0072,  ...,  0.0515,  0.0371, -0.0452],\n",
       "                        [ 0.1831,  0.1592,  0.0572,  ...,  0.1289,  0.1315,  0.2143],\n",
       "                        ...,\n",
       "                        [ 0.0029,  0.0821,  0.0519,  ...,  0.1883,  0.1241,  0.1013],\n",
       "                        [-0.0121, -0.0993, -0.1235,  ...,  0.2072,  0.1706,  0.0504],\n",
       "                        [-0.1634, -0.1207, -0.0111,  ..., -0.0166, -0.0254, -0.0474]]])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.0.bias',\n",
       "               tensor([-0.0536, -0.0362,  0.0683, -0.0318, -0.0636, -0.0344, -0.0430, -0.0442,\n",
       "                       -0.0343, -0.0085,  0.0550, -0.0404, -0.0397, -0.0252, -0.0018,  0.0317,\n",
       "                       -0.0502,  0.0298,  0.0461,  0.0250, -0.0185,  0.0117, -0.0327,  0.0132,\n",
       "                        0.0317, -0.0578,  0.0604,  0.0227, -0.0556,  0.0389, -0.0611,  0.0221,\n",
       "                        0.0379, -0.0210, -0.0553,  0.0009, -0.0270,  0.0132,  0.0214,  0.0570,\n",
       "                       -0.0129, -0.0309,  0.0275, -0.0480, -0.0307,  0.0369, -0.0264,  0.0182,\n",
       "                        0.0343,  0.0008,  0.0278, -0.1336, -0.0330, -0.0390, -0.0530,  0.0213,\n",
       "                        0.0343, -0.0020, -0.0520,  0.0600,  0.0180, -0.0145, -0.0534, -0.0142])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.1.weight',\n",
       "               tensor([0.9593, 0.7192, 0.9892, 0.8373, 1.1083, 0.6374, 0.7919, 0.9184, 0.9980,\n",
       "                       0.8530, 0.7555, 0.6168, 0.8786, 0.9269, 0.7951, 0.8193, 0.8937, 0.9022,\n",
       "                       0.6605, 0.8115, 1.0291, 0.8083, 1.1786, 0.7419, 0.6987, 1.0648, 0.8093,\n",
       "                       0.7838, 0.7344, 1.0245, 0.7085, 1.0915, 1.1354, 0.6110, 0.8228, 0.8593,\n",
       "                       1.0940, 0.8428, 0.8452, 0.6750, 0.9001, 0.9220, 1.1035, 0.9358, 0.8173,\n",
       "                       1.1204, 0.7244, 0.7207, 0.9503, 0.9314, 0.9339, 1.3140, 0.8816, 0.8662,\n",
       "                       0.7123, 0.6502, 1.0819, 0.7072, 0.9190, 0.8410, 0.6009, 0.8235, 0.9797,\n",
       "                       0.8300])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.1.bias',\n",
       "               tensor([-0.7034, -0.3013, -0.2146, -0.1179, -0.4376, -0.4626, -0.1002, -0.1504,\n",
       "                       -0.8303, -0.4569, -0.3584, -0.2494, -0.1841, -0.2932, -0.3476, -0.5602,\n",
       "                       -0.0479, -0.4271, -0.3648, -0.1694, -0.1519, -0.1456, -1.0276, -0.5927,\n",
       "                       -0.6073, -0.4833, -0.7640, -0.2134, -0.2047, -0.4337, -0.5425, -1.0991,\n",
       "                        0.0302, -0.1071, -0.2842, -0.4533, -0.2489, -0.4727, -0.1725, -0.2994,\n",
       "                       -0.1616, -0.1843, -0.6099, -0.2095, -0.5078, -0.1136, -0.4275, -0.5149,\n",
       "                       -0.3854, -0.0600, -0.1601, -0.5778, -0.3966, -0.0882, -0.8294, -0.3140,\n",
       "                       -0.8188, -0.2477, -0.6878, -0.1649, -0.2619, -0.2348, -0.5878, -0.5616])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.1.running_mean',\n",
       "               tensor([-3.6071, -4.3316, -2.2260, -0.6762, -2.6710, -0.7210, -1.4847,  3.2529,\n",
       "                       -0.9363, -1.4030, -0.7099, -2.9287, -3.9667,  0.2526, -0.6072, -1.9930,\n",
       "                       -3.4621, -3.0442,  0.8274, -0.8005, -2.0946, -1.3511, -0.2887, -2.3894,\n",
       "                       -1.2769,  0.5438,  2.1197, -3.5327, -3.5430, -1.5044,  2.1850, -0.1476,\n",
       "                       -4.2542, -2.0784, -4.2088,  0.0064,  1.6965, -0.5745,  0.1889, -2.0529,\n",
       "                       -1.8177, -0.6156,  1.1562, -3.1088, -0.8790,  1.1681, -4.7238, -1.4836,\n",
       "                       -1.8155, -2.6686, -3.2991, -1.7402, -1.0079, -2.4058,  0.3237, -1.4212,\n",
       "                       -1.4807, -4.5370,  2.5863, -1.2840, -1.0989,  2.2541, -0.3931, -0.5787])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.1.running_var',\n",
       "               tensor([ 1.5192, 14.3272,  6.6911, 15.7467,  8.2739,  6.6087, 37.8227,  7.3784,\n",
       "                        1.5310,  3.6433,  5.4392, 11.5073, 21.8930,  4.4306,  5.6404,  3.8165,\n",
       "                       33.9856, 12.5900,  4.1821, 11.9402, 14.7755, 23.0713,  1.5311,  1.8072,\n",
       "                        3.3707,  3.3594,  3.7349, 10.8687, 14.7712,  3.4850, 10.5504,  2.2996,\n",
       "                       15.2878,  4.8251,  9.5947,  3.2586,  8.1507,  3.7275,  2.6100,  7.7057,\n",
       "                        9.2835,  6.3605,  9.8145,  9.5901,  1.4758, 10.9617,  6.7446,  3.3084,\n",
       "                        3.6585, 19.1548, 11.6217,  2.2902,  3.0095,  9.7415,  2.4253, 21.0049,\n",
       "                        3.5471, 10.3012,  5.3927, 25.5759,  4.9158, 10.8099,  4.2931,  2.9756])),\n",
       "              ('variational_encoder.encoder.cnn.2.0.1.num_batches_tracked',\n",
       "               tensor(44082)),\n",
       "              ('variational_encoder.encoder.fc.1.weight',\n",
       "               tensor([[ 0.0264,  0.0048,  0.0265,  ...,  0.0256, -0.0275,  0.0674],\n",
       "                       [-0.0241, -0.0588, -0.0562,  ...,  0.0118,  0.0175,  0.0435],\n",
       "                       [-0.0376,  0.0209,  0.0265,  ..., -0.0068, -0.0829,  0.0760]])),\n",
       "              ('variational_encoder.encoder.fc.1.bias',\n",
       "               tensor([ 0.0656, -0.0955, -0.0875])),\n",
       "              ('variational_encoder.fc_location.weight',\n",
       "               tensor([[ 0.0182,  0.1347, -0.0995],\n",
       "                       [ 0.1135, -0.1980, -0.0147],\n",
       "                       [-0.0899, -0.1113, -0.0895]])),\n",
       "              ('variational_encoder.fc_location.bias',\n",
       "               tensor([-1.0471, -1.1233, -1.0752])),\n",
       "              ('variational_encoder.fc_scale.weight',\n",
       "               tensor([[ 0.0696, -3.1286, -4.6501]])),\n",
       "              ('variational_encoder.fc_scale.bias', tensor([8.5930]))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 44082},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 44082,\n",
       "     'completed': 44082,\n",
       "     'started': 44082,\n",
       "     'processed': 44082},\n",
       "    'current': {'ready': 237,\n",
       "     'completed': 237,\n",
       "     'started': 237,\n",
       "     'processed': 237},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 44082,\n",
       "       'completed': 44082},\n",
       "      'current': {'ready': 237, 'completed': 237}},\n",
       "     'zero_grad': {'total': {'ready': 44082,\n",
       "       'completed': 44082,\n",
       "       'started': 44082},\n",
       "      'current': {'ready': 237, 'completed': 237, 'started': 237}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False},\n",
       "   'epoch_progress': {'total': {'ready': 186,\n",
       "     'completed': 185,\n",
       "     'started': 186,\n",
       "     'processed': 186},\n",
       "    'current': {'ready': 186,\n",
       "     'completed': 185,\n",
       "     'started': 186,\n",
       "     'processed': 186}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': 'train_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'train_loss',\n",
       "   'best_model_score': tensor(0.0089),\n",
       "   'best_model_path': './gaia/qf4roy5i/checkpoints/epoch=185-train_loss=0.01.ckpt',\n",
       "   'current_score': tensor(0.0089),\n",
       "   'dirpath': './gaia/qf4roy5i/checkpoints',\n",
       "   'best_k_models': {'./gaia/qf4roy5i/checkpoints/epoch=185-train_loss=0.01.ckpt': tensor(0.0089)},\n",
       "   'kth_best_model_path': './gaia/qf4roy5i/checkpoints/epoch=185-train_loss=0.01.ckpt',\n",
       "   'kth_value': tensor(0.0089),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[[-2.2536e-07,  1.3999e-07,  2.7361e-07, -3.0779e-09, -4.0321e-07]],\n",
       "     \n",
       "             [[-7.8438e-07, -4.7489e-07,  4.5579e-07,  5.7413e-07, -4.7932e-07]],\n",
       "     \n",
       "             [[-1.3627e-05, -1.1888e-05, -1.2871e-05, -1.5473e-05, -1.7176e-05]],\n",
       "     \n",
       "             [[ 4.0915e-08,  1.7520e-07,  2.4064e-07, -3.6073e-10, -8.7338e-08]],\n",
       "     \n",
       "             [[-1.8429e-06, -1.7214e-06, -1.0753e-06, -3.2241e-07,  2.4493e-07]],\n",
       "     \n",
       "             [[-1.0291e-06, -1.2449e-06, -1.3811e-06, -1.9869e-06, -2.8921e-06]],\n",
       "     \n",
       "             [[-2.4632e-07, -7.7088e-08,  6.9051e-08,  1.4363e-07,  6.5725e-08]],\n",
       "     \n",
       "             [[ 1.9240e-06,  2.1876e-06,  1.2612e-06,  5.7013e-07,  8.1440e-08]],\n",
       "     \n",
       "             [[ 2.1249e-06,  7.6241e-06,  5.7805e-06, -4.9724e-07, -5.8937e-06]],\n",
       "     \n",
       "             [[-8.4303e-08, -2.3571e-08,  6.0600e-08,  6.0976e-08,  4.2685e-08]],\n",
       "     \n",
       "             [[-4.5804e-08,  8.0785e-08, -5.1525e-08, -3.4311e-07, -6.4838e-07]],\n",
       "     \n",
       "             [[ 1.2926e-05,  1.5092e-05,  1.6286e-05,  1.5421e-05,  1.2133e-05]],\n",
       "     \n",
       "             [[-4.6507e-07,  9.4531e-08,  4.5274e-07,  2.8989e-07, -8.7873e-08]],\n",
       "     \n",
       "             [[ 1.5760e-07, -5.6981e-07, -2.2843e-07,  3.5352e-07,  4.0432e-07]],\n",
       "     \n",
       "             [[-6.2894e-07, -2.2864e-07,  3.8580e-07,  8.6291e-07,  7.8789e-07]],\n",
       "     \n",
       "             [[-3.8712e-08, -5.6759e-07, -1.2880e-06, -1.8823e-06, -2.0384e-06]]]),\n",
       "     'exp_avg_sq': tensor([[[2.1190e-12, 2.3688e-12, 5.9493e-13, 3.3599e-12, 1.0279e-11]],\n",
       "     \n",
       "             [[2.1325e-08, 2.0943e-08, 1.9582e-08, 1.8273e-08, 1.7909e-08]],\n",
       "     \n",
       "             [[1.5867e-09, 1.2436e-09, 1.5440e-09, 2.2885e-09, 2.7208e-09]],\n",
       "     \n",
       "             [[1.5765e-11, 7.5845e-11, 1.7805e-10, 9.9879e-11, 6.2587e-11]],\n",
       "     \n",
       "             [[2.0643e-10, 3.3962e-10, 3.9993e-10, 2.7884e-10, 2.1705e-10]],\n",
       "     \n",
       "             [[2.5188e-10, 2.8011e-10, 3.9585e-10, 4.9206e-10, 4.8544e-10]],\n",
       "     \n",
       "             [[7.2519e-12, 5.8083e-12, 3.6649e-12, 7.2550e-13, 2.2936e-12]],\n",
       "     \n",
       "             [[2.3301e-09, 2.4705e-09, 2.5792e-09, 2.5684e-09, 2.5199e-09]],\n",
       "     \n",
       "             [[3.5334e-09, 5.8268e-09, 7.8416e-09, 5.5030e-09, 3.4109e-09]],\n",
       "     \n",
       "             [[1.0753e-12, 1.2596e-12, 7.0484e-13, 1.4262e-12, 8.0538e-12]],\n",
       "     \n",
       "             [[8.6707e-13, 3.9951e-13, 8.7771e-13, 7.8715e-12, 1.8757e-11]],\n",
       "     \n",
       "             [[7.7983e-08, 7.6634e-08, 7.6600e-08, 7.7324e-08, 7.6537e-08]],\n",
       "     \n",
       "             [[7.9347e-12, 5.1788e-12, 3.0609e-12, 3.0702e-12, 1.0337e-11]],\n",
       "     \n",
       "             [[1.8118e-11, 4.3067e-12, 1.5093e-10, 2.9911e-10, 2.3865e-10]],\n",
       "     \n",
       "             [[2.6673e-11, 4.0394e-11, 7.9387e-11, 5.4242e-11, 1.8374e-11]],\n",
       "     \n",
       "             [[2.1053e-12, 1.9474e-11, 7.1916e-11, 1.0660e-10, 9.7363e-11]]])},\n",
       "    1: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 6.6724e-10, -3.0406e-09, -6.1926e-09, -1.8450e-09,  1.4742e-09,\n",
       "             -1.5743e-10,  6.9228e-10,  1.8151e-08, -9.8286e-09, -1.9373e-09,\n",
       "             -2.3888e-09,  3.8228e-08, -2.3230e-09, -4.1419e-09,  1.2453e-08,\n",
       "              1.4195e-09]),\n",
       "     'exp_avg_sq': tensor([3.1172e-17, 5.5283e-15, 9.3835e-16, 4.3433e-16, 9.7528e-16, 1.7104e-16,\n",
       "             5.7982e-17, 1.0764e-13, 3.5137e-13, 2.1616e-17, 1.2186e-16, 3.8407e-14,\n",
       "             9.3872e-17, 2.3885e-16, 4.5477e-15, 2.8938e-16])},\n",
       "    2: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 1.8178e-07,  3.8800e-06,  1.2690e-06,  4.0663e-07,  2.4240e-06,\n",
       "              2.0137e-07,  4.0312e-07, -9.1489e-07, -2.3711e-07, -1.6766e-06,\n",
       "              4.2814e-08, -6.9169e-06, -1.9349e-06, -2.7525e-06, -1.2771e-06,\n",
       "              8.7503e-07]),\n",
       "     'exp_avg_sq': tensor([4.1466e-10, 4.3673e-10, 1.8652e-10, 1.8667e-10, 3.6828e-10, 1.5932e-10,\n",
       "             4.3826e-10, 7.7766e-11, 1.6603e-09, 1.0561e-09, 8.5265e-10, 5.8914e-10,\n",
       "             3.5186e-10, 4.4832e-10, 9.6546e-10, 2.9131e-10])},\n",
       "    3: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-7.6311e-07, -4.9568e-07,  1.1502e-06, -3.3898e-06,  4.8388e-06,\n",
       "             -8.7932e-07,  1.1076e-06,  9.6372e-07,  5.5549e-06, -1.9419e-06,\n",
       "              1.8363e-06,  5.7958e-08, -6.9141e-06, -6.7695e-06,  7.2386e-06,\n",
       "              3.8520e-06]),\n",
       "     'exp_avg_sq': tensor([3.8209e-09, 5.0875e-10, 6.9196e-10, 2.7608e-09, 6.2351e-10, 1.6481e-10,\n",
       "             3.4091e-09, 2.0712e-11, 2.4789e-09, 1.8284e-10, 1.2828e-09, 1.7968e-10,\n",
       "             1.3671e-09, 1.4839e-09, 2.9493e-09, 3.6950e-09])},\n",
       "    4: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[[ 4.5534e-07,  4.9950e-07,  5.8356e-07,  ...,  3.3638e-07,\n",
       "                4.1727e-07,  7.1642e-07],\n",
       "              [-1.8157e-06, -1.4986e-06, -2.1874e-06,  ..., -1.4900e-06,\n",
       "               -6.5953e-07,  1.8218e-08],\n",
       "              [-1.8542e-06, -1.8661e-06, -2.7853e-06,  ..., -1.5709e-06,\n",
       "               -1.0522e-06, -1.2900e-06],\n",
       "              ...,\n",
       "              [-4.3490e-07, -4.3972e-07, -3.9309e-07,  ..., -4.8773e-07,\n",
       "               -4.1953e-07, -3.5586e-07],\n",
       "              [-7.9545e-07, -9.0710e-07, -8.4512e-07,  ..., -6.2348e-07,\n",
       "               -6.2322e-07, -7.3336e-07],\n",
       "              [ 1.5935e-07,  3.1255e-07,  4.0752e-07,  ...,  4.0888e-07,\n",
       "                3.6947e-07,  2.8235e-07]],\n",
       "     \n",
       "             [[ 2.8975e-08,  2.5161e-08,  3.5744e-08,  ..., -4.1820e-09,\n",
       "               -2.8331e-08, -5.3366e-08],\n",
       "              [ 4.1031e-07,  4.0249e-07,  3.3689e-07,  ...,  2.7043e-07,\n",
       "                2.2212e-07,  2.1775e-07],\n",
       "              [ 3.0931e-07,  2.7109e-07,  2.3929e-07,  ...,  2.3981e-07,\n",
       "                2.6882e-07,  2.6171e-07],\n",
       "              ...,\n",
       "              [ 8.3515e-08,  6.8897e-08,  7.9666e-08,  ...,  6.8603e-08,\n",
       "                5.1330e-08,  4.7981e-08],\n",
       "              [ 3.4526e-07,  3.4941e-07,  3.5454e-07,  ...,  3.3293e-07,\n",
       "                3.1294e-07,  2.8842e-07],\n",
       "              [ 8.8573e-09, -1.9266e-08, -3.5621e-08,  ..., -4.4614e-08,\n",
       "               -7.5239e-08, -1.1202e-07]],\n",
       "     \n",
       "             [[ 7.7028e-08,  1.7516e-07,  2.4210e-07,  ...,  3.7560e-07,\n",
       "                4.1935e-07,  4.7995e-07],\n",
       "              [-1.3071e-07, -2.2988e-08, -6.2214e-08,  ..., -8.6963e-09,\n",
       "               -1.2846e-07, -9.7161e-08],\n",
       "              [ 3.1065e-07,  4.0544e-07,  3.4213e-07,  ...,  2.8206e-07,\n",
       "                2.5193e-07,  3.0216e-07],\n",
       "              ...,\n",
       "              [ 3.4601e-07,  4.2878e-07,  4.9509e-07,  ...,  6.0709e-07,\n",
       "                6.9498e-07,  7.8688e-07],\n",
       "              [ 7.1133e-07,  7.4049e-07,  7.2481e-07,  ...,  7.7458e-07,\n",
       "                6.7009e-07,  7.2521e-07],\n",
       "              [-8.6685e-08, -6.1027e-08,  8.6594e-09,  ...,  6.4661e-08,\n",
       "                1.0198e-07,  1.8405e-07]],\n",
       "     \n",
       "             ...,\n",
       "     \n",
       "             [[ 2.3726e-07,  2.3344e-07,  2.1559e-07,  ...,  2.4304e-07,\n",
       "                2.5614e-07,  2.6874e-07],\n",
       "              [ 8.7189e-07,  5.5922e-07,  4.3903e-07,  ...,  9.7776e-07,\n",
       "                8.2072e-07,  3.9984e-07],\n",
       "              [ 2.4971e-07,  6.9549e-09,  1.0487e-07,  ...,  2.1714e-07,\n",
       "                5.0697e-08, -1.0848e-07],\n",
       "              ...,\n",
       "              [ 1.5455e-07,  1.3900e-07,  1.2714e-07,  ...,  1.3438e-07,\n",
       "                1.4758e-07,  1.5832e-07],\n",
       "              [-3.9071e-08, -1.1448e-07, -1.0224e-07,  ..., -1.2525e-07,\n",
       "               -5.6541e-08, -4.5755e-08],\n",
       "              [ 2.6842e-07,  2.6543e-07,  2.5633e-07,  ...,  2.5159e-07,\n",
       "                2.4400e-07,  2.6073e-07]],\n",
       "     \n",
       "             [[-3.7789e-08, -4.4858e-08, -6.9451e-08,  ..., -1.0360e-07,\n",
       "               -1.0333e-07, -1.2931e-07],\n",
       "              [ 7.2179e-08, -5.6113e-08, -1.1686e-07,  ...,  9.5215e-08,\n",
       "               -8.8363e-08, -3.9709e-08],\n",
       "              [ 2.2159e-07,  1.7944e-07,  1.4279e-07,  ...,  2.6134e-07,\n",
       "                1.3751e-07,  1.8364e-07],\n",
       "              ...,\n",
       "              [ 1.9969e-08,  2.4198e-08,  1.6965e-08,  ..., -5.9386e-08,\n",
       "               -3.9112e-08, -5.9799e-08],\n",
       "              [ 1.7797e-07,  1.6815e-07,  1.8063e-07,  ...,  1.7210e-07,\n",
       "                1.6656e-07,  1.5253e-07],\n",
       "              [-2.1015e-08, -1.9982e-08, -1.9469e-08,  ..., -8.4888e-08,\n",
       "               -7.3521e-08, -6.8577e-08]],\n",
       "     \n",
       "             [[ 1.9117e-07,  2.5961e-07,  3.2194e-07,  ...,  3.3115e-07,\n",
       "                4.0537e-07,  4.6891e-07],\n",
       "              [-4.6961e-08, -5.3617e-08, -9.2517e-08,  ...,  5.5908e-09,\n",
       "               -1.0452e-09,  2.1234e-08],\n",
       "              [-1.5975e-08,  1.5618e-08, -1.2581e-07,  ..., -7.5885e-08,\n",
       "               -1.6679e-07, -1.3498e-07],\n",
       "              ...,\n",
       "              [ 1.6054e-07,  2.0560e-07,  2.3628e-07,  ...,  2.4273e-07,\n",
       "                2.6281e-07,  3.2360e-07],\n",
       "              [ 2.3983e-07,  1.9323e-07,  1.5260e-07,  ...,  1.3214e-07,\n",
       "                1.3489e-07,  1.0209e-07],\n",
       "              [ 6.7990e-08,  1.3704e-07,  1.7896e-07,  ...,  2.4330e-07,\n",
       "                2.2966e-07,  3.5251e-07]]]),\n",
       "     'exp_avg_sq': tensor([[[1.0146e-10, 9.1261e-11, 8.7316e-11,  ..., 8.0422e-11,\n",
       "               7.8420e-11, 7.7515e-11],\n",
       "              [1.5145e-10, 1.8070e-10, 1.7607e-10,  ..., 1.4439e-10,\n",
       "               1.2124e-10, 6.1373e-11],\n",
       "              [9.7168e-11, 1.0918e-10, 9.6076e-11,  ..., 7.8586e-11,\n",
       "               6.3641e-11, 5.4389e-11],\n",
       "              ...,\n",
       "              [9.2011e-11, 7.6512e-11, 6.6091e-11,  ..., 5.6379e-11,\n",
       "               5.1127e-11, 4.8929e-11],\n",
       "              [4.9972e-11, 5.1103e-11, 5.4949e-11,  ..., 7.2664e-11,\n",
       "               8.8502e-11, 1.0682e-10],\n",
       "              [6.1162e-11, 5.3803e-11, 4.6309e-11,  ..., 4.6129e-11,\n",
       "               4.4252e-11, 4.5797e-11]],\n",
       "     \n",
       "             [[3.2152e-13, 1.6528e-13, 1.6583e-13,  ..., 5.0103e-13,\n",
       "               4.1831e-13, 4.1088e-13],\n",
       "              [3.0047e-12, 2.1753e-12, 1.5451e-12,  ..., 1.8229e-12,\n",
       "               3.3949e-12, 3.0955e-12],\n",
       "              [1.2214e-11, 1.0861e-11, 9.9246e-12,  ..., 1.3469e-11,\n",
       "               1.3232e-11, 1.2683e-11],\n",
       "              ...,\n",
       "              [3.8873e-12, 3.5429e-12, 3.4569e-12,  ..., 3.4872e-12,\n",
       "               3.3701e-12, 2.7314e-12],\n",
       "              [5.7527e-11, 6.0608e-11, 6.4562e-11,  ..., 7.2064e-11,\n",
       "               7.1869e-11, 7.1050e-11],\n",
       "              [6.4488e-13, 8.6521e-13, 1.0449e-12,  ..., 9.9845e-13,\n",
       "               8.1069e-13, 1.1953e-12]],\n",
       "     \n",
       "             [[1.5543e-12, 1.4825e-12, 1.6461e-12,  ..., 2.8098e-12,\n",
       "               4.3622e-12, 5.9077e-12],\n",
       "              [7.4448e-12, 6.6073e-12, 8.0354e-12,  ..., 3.1895e-12,\n",
       "               5.2739e-12, 1.1832e-11],\n",
       "              [1.0317e-11, 9.4073e-12, 1.0146e-11,  ..., 8.2578e-12,\n",
       "               8.5939e-12, 8.1470e-12],\n",
       "              ...,\n",
       "              [8.3655e-12, 8.1655e-12, 8.4853e-12,  ..., 9.1163e-12,\n",
       "               9.7744e-12, 1.1782e-11],\n",
       "              [1.3980e-11, 1.3874e-11, 1.4124e-11,  ..., 1.4244e-11,\n",
       "               1.5055e-11, 1.4669e-11],\n",
       "              [7.8387e-13, 4.7852e-13, 4.1891e-13,  ..., 3.7190e-13,\n",
       "               1.0224e-12, 1.5819e-12]],\n",
       "     \n",
       "             ...,\n",
       "     \n",
       "             [[1.7273e-11, 1.7367e-11, 1.7288e-11,  ..., 1.6148e-11,\n",
       "               1.5702e-11, 1.5389e-11],\n",
       "              [6.5929e-12, 7.1939e-12, 4.5798e-12,  ..., 3.6390e-12,\n",
       "               7.9634e-12, 4.8860e-12],\n",
       "              [3.7179e-12, 4.9679e-12, 2.4106e-12,  ..., 5.6977e-12,\n",
       "               7.8612e-12, 3.3986e-12],\n",
       "              ...,\n",
       "              [1.0074e-11, 1.0144e-11, 1.0152e-11,  ..., 9.5914e-12,\n",
       "               9.1307e-12, 8.9914e-12],\n",
       "              [4.3393e-12, 4.6045e-12, 5.5650e-12,  ..., 4.8560e-12,\n",
       "               4.9901e-12, 4.7803e-12],\n",
       "              [1.2042e-11, 1.2008e-11, 1.1888e-11,  ..., 1.1416e-11,\n",
       "               1.0752e-11, 1.0634e-11]],\n",
       "     \n",
       "             [[4.7458e-13, 3.9022e-13, 3.3232e-13,  ..., 4.6422e-13,\n",
       "               7.4108e-13, 1.2779e-12],\n",
       "              [1.8376e-12, 8.7877e-13, 3.3976e-12,  ..., 1.5897e-12,\n",
       "               9.9791e-13, 1.6077e-12],\n",
       "              [1.8166e-12, 1.8967e-12, 2.3404e-12,  ..., 2.4145e-12,\n",
       "               1.9171e-12, 2.3891e-12],\n",
       "              ...,\n",
       "              [7.3897e-13, 1.0216e-12, 4.5410e-13,  ..., 5.0351e-13,\n",
       "               3.3523e-13, 4.1102e-13],\n",
       "              [3.0812e-12, 3.0056e-12, 3.1178e-12,  ..., 2.8804e-12,\n",
       "               2.5529e-12, 2.2197e-12],\n",
       "              [2.8508e-13, 6.0605e-13, 2.5340e-13,  ..., 3.1115e-13,\n",
       "               3.4342e-13, 5.4459e-13]],\n",
       "     \n",
       "             [[4.9417e-11, 5.0159e-11, 5.5002e-11,  ..., 6.5533e-11,\n",
       "               7.1071e-11, 7.6046e-11],\n",
       "              [6.5133e-12, 1.0829e-11, 1.2332e-11,  ..., 9.7917e-12,\n",
       "               8.6074e-12, 9.5903e-12],\n",
       "              [8.9020e-13, 1.0013e-12, 1.1322e-12,  ..., 1.9778e-12,\n",
       "               1.8859e-12, 2.4633e-12],\n",
       "              ...,\n",
       "              [2.8500e-11, 2.9198e-11, 3.1335e-11,  ..., 3.8274e-11,\n",
       "               4.2776e-11, 4.7290e-11],\n",
       "              [6.5212e-12, 6.8783e-12, 7.1177e-12,  ..., 8.0241e-12,\n",
       "               9.6284e-12, 1.1589e-11],\n",
       "              [2.7099e-11, 2.5757e-11, 2.5120e-11,  ..., 3.0592e-11,\n",
       "               3.2329e-11, 3.4493e-11]]])},\n",
       "    5: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-2.2375e-10, -4.7979e-11,  1.3234e-10, -2.8224e-10, -4.3438e-10,\n",
       "              2.5375e-10, -2.3703e-12, -4.7891e-11, -2.4884e-10,  6.1424e-11,\n",
       "             -7.3664e-11, -9.6551e-12, -2.2256e-10, -2.0396e-10,  8.1217e-11,\n",
       "             -1.2771e-09, -2.1370e-10,  5.9219e-11, -6.1417e-11,  3.1220e-10,\n",
       "              1.4458e-10,  2.0016e-10, -4.9845e-11, -5.7952e-11,  1.0718e-10,\n",
       "             -4.7299e-10, -1.3222e-09, -8.9829e-12,  2.2360e-10, -1.5700e-10,\n",
       "              2.8260e-11,  1.6322e-10]),\n",
       "     'exp_avg_sq': tensor([4.3598e-18, 4.8285e-19, 1.6681e-19, 1.4370e-18, 3.4732e-18, 2.0907e-18,\n",
       "             8.7839e-20, 3.4017e-18, 4.3095e-19, 1.0170e-19, 3.4196e-19, 2.4805e-18,\n",
       "             3.4821e-18, 9.6066e-19, 1.5633e-19, 5.2214e-18, 3.6056e-18, 4.7058e-19,\n",
       "             9.4671e-20, 4.7281e-18, 3.4129e-18, 1.6051e-19, 3.9979e-20, 1.5685e-19,\n",
       "             2.1314e-19, 1.6901e-18, 1.8745e-17, 1.6894e-19, 1.0527e-17, 1.5487e-18,\n",
       "             1.0667e-19, 4.4618e-19])},\n",
       "    6: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 3.5387e-06,  1.4313e-07,  2.1051e-07, -2.5799e-06, -1.9076e-06,\n",
       "             -2.2597e-06, -2.8635e-07, -1.5834e-06, -4.4102e-06,  3.1090e-06,\n",
       "              2.9103e-06, -1.2026e-06,  2.0876e-06, -7.3070e-08,  1.6169e-06,\n",
       "             -7.7124e-06, -1.2046e-06,  3.1967e-06,  7.8115e-07, -1.1277e-06,\n",
       "             -2.0431e-06,  1.1814e-06,  7.4314e-07,  1.2421e-06,  2.3035e-06,\n",
       "              8.4233e-07,  1.2605e-06,  9.0496e-07, -4.3904e-06,  1.0418e-06,\n",
       "             -1.4857e-06,  6.4258e-06]),\n",
       "     'exp_avg_sq': tensor([9.3823e-10, 8.6480e-10, 5.2489e-10, 1.0420e-10, 1.5169e-10, 6.2375e-10,\n",
       "             1.1605e-09, 5.8473e-10, 2.7647e-09, 8.6966e-10, 6.3885e-10, 1.1213e-09,\n",
       "             6.0640e-10, 5.6588e-10, 5.4306e-10, 1.5957e-09, 2.6666e-10, 2.9800e-10,\n",
       "             5.5878e-10, 4.4000e-10, 7.6710e-10, 3.4744e-10, 4.6886e-10, 1.0859e-09,\n",
       "             8.3843e-10, 2.5457e-10, 4.8576e-10, 9.2954e-10, 8.3559e-10, 8.2326e-10,\n",
       "             1.6813e-09, 1.5188e-09])},\n",
       "    7: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 3.8087e-06, -1.0645e-06, -6.4571e-06, -2.8537e-06, -1.3310e-06,\n",
       "              5.6179e-07, -3.0108e-07,  2.4750e-06, -1.9396e-06, -3.0685e-06,\n",
       "              3.3089e-06,  2.8304e-06,  5.2617e-06, -3.3290e-07, -7.2025e-07,\n",
       "             -4.3554e-06, -2.6192e-06, -2.3647e-07,  4.5802e-07, -2.3954e-06,\n",
       "             -1.3795e-06, -2.3954e-06, -2.9525e-06,  7.7189e-07, -6.4935e-08,\n",
       "              7.0645e-07,  7.6258e-07, -6.8861e-07, -5.7325e-06, -1.3142e-06,\n",
       "             -1.1294e-06,  3.0627e-06]),\n",
       "     'exp_avg_sq': tensor([6.7369e-10, 6.8550e-10, 1.2603e-09, 2.4793e-10, 1.6642e-10, 5.2378e-10,\n",
       "             1.6513e-10, 2.4721e-10, 3.3592e-10, 5.5751e-10, 5.1200e-10, 1.6076e-09,\n",
       "             8.7893e-10, 7.9971e-10, 4.8567e-10, 5.1947e-10, 4.9413e-10, 2.9820e-10,\n",
       "             8.3625e-11, 7.5213e-10, 1.2207e-09, 4.0013e-10, 6.3359e-10, 1.7187e-10,\n",
       "             1.3905e-10, 2.6115e-10, 8.1040e-10, 3.4157e-10, 1.6421e-09, 1.2771e-09,\n",
       "             2.0494e-10, 1.0078e-09])},\n",
       "    8: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[[ 6.5436e-08,  5.1385e-07,  6.6586e-07,  ..., -3.0489e-07,\n",
       "               -9.6712e-08, -1.8243e-07],\n",
       "              [ 1.1214e-07,  2.6307e-07,  2.4259e-07,  ...,  2.7924e-07,\n",
       "                2.9536e-07,  3.8175e-07],\n",
       "              [ 3.6673e-07,  3.6534e-07,  3.4109e-07,  ...,  2.4770e-07,\n",
       "                2.8939e-07,  3.6980e-07],\n",
       "              ...,\n",
       "              [ 3.2815e-07,  3.7822e-07,  4.3709e-07,  ...,  4.9255e-07,\n",
       "                2.8595e-07,  2.3201e-07],\n",
       "              [ 2.7142e-07,  2.0504e-07,  1.1634e-07,  ...,  1.6813e-07,\n",
       "                1.7660e-07,  2.3346e-07],\n",
       "              [-3.5404e-07, -3.6318e-07, -3.4503e-07,  ..., -3.3072e-07,\n",
       "               -2.9870e-07, -2.7294e-07]],\n",
       "     \n",
       "             [[-4.8890e-07, -2.9758e-07, -4.1102e-07,  ..., -7.2461e-07,\n",
       "               -6.1883e-07, -2.5763e-07],\n",
       "              [ 1.7036e-07,  1.6519e-07,  1.8081e-07,  ...,  3.3305e-08,\n",
       "                3.2104e-08, -7.3923e-08],\n",
       "              [-4.2718e-07, -3.1715e-07, -2.8692e-07,  ..., -5.8146e-08,\n",
       "                4.3433e-08,  1.0453e-07],\n",
       "              ...,\n",
       "              [-6.9956e-08, -7.3943e-08, -8.4527e-08,  ..., -7.7867e-08,\n",
       "               -8.0326e-08, -7.9282e-08],\n",
       "              [-1.8893e-07, -9.2962e-08, -1.0676e-07,  ...,  1.3890e-07,\n",
       "                1.6031e-07,  1.4884e-07],\n",
       "              [-3.0075e-07, -2.2420e-07, -1.8794e-07,  ..., -9.2248e-08,\n",
       "               -1.7872e-08,  4.8320e-08]],\n",
       "     \n",
       "             [[ 4.6044e-07,  4.9864e-07,  4.3324e-07,  ...,  2.3840e-07,\n",
       "                3.0646e-08,  3.9524e-08],\n",
       "              [-2.2280e-07, -2.4667e-07, -2.6249e-07,  ..., -2.9676e-07,\n",
       "               -2.5460e-07, -3.2994e-07],\n",
       "              [-4.5582e-08, -7.9414e-09, -9.6881e-09,  ..., -2.6797e-09,\n",
       "                1.3644e-08,  2.1003e-08],\n",
       "              ...,\n",
       "              [ 1.8451e-07,  3.0870e-07,  4.4224e-07,  ...,  5.7838e-07,\n",
       "                6.3272e-07,  4.5336e-07],\n",
       "              [-3.6808e-08, -5.7876e-08, -6.6853e-08,  ..., -2.7169e-08,\n",
       "               -3.1626e-08, -1.5164e-08],\n",
       "              [ 6.5676e-07,  6.5089e-07,  6.8293e-07,  ...,  6.9958e-07,\n",
       "                6.8897e-07,  6.5876e-07]],\n",
       "     \n",
       "             ...,\n",
       "     \n",
       "             [[ 3.5691e-08,  1.7447e-07, -1.9109e-08,  ..., -3.9783e-07,\n",
       "               -2.5683e-07,  1.6908e-07],\n",
       "              [ 7.1759e-08,  8.5360e-08,  3.7499e-08,  ...,  8.3961e-08,\n",
       "                6.0768e-08,  4.8155e-08],\n",
       "              [ 1.4346e-08, -1.1153e-07, -9.0819e-08,  ..., -1.5422e-07,\n",
       "               -1.2615e-07, -1.2206e-07],\n",
       "              ...,\n",
       "              [-5.0701e-07, -5.2589e-07, -4.4988e-07,  ..., -6.7672e-08,\n",
       "                3.0377e-08,  2.3110e-07],\n",
       "              [-1.0380e-07, -1.3674e-07, -8.9586e-08,  ..., -5.4703e-08,\n",
       "               -3.4229e-08, -5.1537e-08],\n",
       "              [-1.6421e-08, -6.2657e-08, -8.5978e-08,  ..., -2.2899e-07,\n",
       "               -2.7848e-07, -1.8814e-07]],\n",
       "     \n",
       "             [[-3.4301e-09,  5.6799e-07,  5.5314e-07,  ..., -4.3157e-09,\n",
       "               -3.5882e-07, -1.9335e-07],\n",
       "              [ 1.6268e-07,  9.5064e-08,  5.0900e-08,  ...,  5.8554e-08,\n",
       "                1.6967e-07,  7.9059e-08],\n",
       "              [ 1.7068e-07,  2.2251e-07,  1.3966e-07,  ..., -1.7192e-08,\n",
       "               -1.0628e-08, -1.8923e-08],\n",
       "              ...,\n",
       "              [ 5.5504e-08,  5.3160e-08,  7.5330e-08,  ...,  9.7512e-08,\n",
       "                3.6361e-08, -2.1122e-07],\n",
       "              [-5.3360e-09, -1.5126e-08, -2.6109e-08,  ..., -3.2358e-08,\n",
       "               -3.3722e-08, -3.5401e-08],\n",
       "              [-5.4665e-07, -3.9532e-07, -3.2973e-07,  ..., -5.4082e-07,\n",
       "               -5.6487e-07, -5.3011e-07]],\n",
       "     \n",
       "             [[ 8.8804e-09, -1.0141e-08,  6.5820e-08,  ...,  1.2071e-08,\n",
       "                3.6610e-08,  1.7898e-07],\n",
       "              [ 9.3942e-08,  1.1263e-07,  7.1458e-08,  ...,  1.1510e-07,\n",
       "                1.3043e-07,  1.6979e-07],\n",
       "              [-1.1168e-07, -1.0579e-07, -8.9884e-08,  ..., -9.0855e-08,\n",
       "               -8.7671e-08, -9.4836e-08],\n",
       "              ...,\n",
       "              [-9.3085e-08, -7.6693e-08, -7.3583e-08,  ..., -9.9569e-08,\n",
       "               -8.8110e-08, -5.2564e-08],\n",
       "              [ 2.5759e-08,  5.3990e-08,  4.9991e-08,  ...,  3.2780e-08,\n",
       "                2.1686e-08,  7.1393e-09],\n",
       "              [-9.7965e-08, -1.0579e-07, -1.3683e-07,  ..., -2.6831e-07,\n",
       "               -2.7975e-07, -2.5270e-07]]]),\n",
       "     'exp_avg_sq': tensor([[[4.9425e-11, 5.6876e-11, 4.9920e-11,  ..., 4.1028e-11,\n",
       "               4.4537e-11, 4.9334e-11],\n",
       "              [1.0842e-11, 1.1168e-11, 1.1187e-11,  ..., 1.0101e-11,\n",
       "               9.3118e-12, 8.1714e-12],\n",
       "              [2.0841e-11, 1.8432e-11, 1.6081e-11,  ..., 1.1514e-11,\n",
       "               1.1832e-11, 1.2245e-11],\n",
       "              ...,\n",
       "              [6.9252e-12, 6.8856e-12, 6.8776e-12,  ..., 6.2091e-12,\n",
       "               5.8761e-12, 5.3582e-12],\n",
       "              [1.2888e-11, 1.0350e-11, 8.9819e-12,  ..., 6.9732e-12,\n",
       "               7.4233e-12, 8.0210e-12],\n",
       "              [2.5546e-11, 2.4810e-11, 2.5197e-11,  ..., 2.2696e-11,\n",
       "               2.0188e-11, 1.8008e-11]],\n",
       "     \n",
       "             [[1.2518e-11, 9.2982e-12, 1.0523e-11,  ..., 7.5884e-12,\n",
       "               3.3853e-12, 1.7667e-12],\n",
       "              [8.5267e-13, 9.0483e-13, 9.6913e-13,  ..., 9.7834e-13,\n",
       "               1.1734e-12, 1.4308e-12],\n",
       "              [4.4726e-12, 3.7037e-12, 3.2753e-12,  ..., 2.9738e-12,\n",
       "               2.8461e-12, 2.8273e-12],\n",
       "              ...,\n",
       "              [5.1888e-13, 6.2618e-13, 7.1992e-13,  ..., 7.2351e-13,\n",
       "               6.4285e-13, 6.1391e-13],\n",
       "              [1.6483e-12, 1.7568e-12, 1.9067e-12,  ..., 2.2115e-12,\n",
       "               2.4764e-12, 2.7302e-12],\n",
       "              [1.5797e-12, 1.5985e-12, 1.5096e-12,  ..., 1.5364e-12,\n",
       "               1.7487e-12, 2.0032e-12]],\n",
       "     \n",
       "             [[9.1538e-12, 7.5400e-12, 9.7120e-12,  ..., 4.5253e-12,\n",
       "               5.1476e-12, 5.6418e-12],\n",
       "              [4.2116e-12, 4.6323e-12, 4.6777e-12,  ..., 7.3785e-12,\n",
       "               7.4696e-12, 8.0301e-12],\n",
       "              [1.2455e-12, 1.2352e-12, 1.2126e-12,  ..., 1.1880e-12,\n",
       "               1.3811e-12, 1.4379e-12],\n",
       "              ...,\n",
       "              [3.4004e-11, 3.5063e-11, 3.5110e-11,  ..., 4.0039e-11,\n",
       "               4.3954e-11, 4.8425e-11],\n",
       "              [2.2510e-12, 2.2008e-12, 2.0803e-12,  ..., 9.0059e-13,\n",
       "               7.7289e-13, 7.2123e-13],\n",
       "              [1.6289e-11, 1.6583e-11, 1.7070e-11,  ..., 1.9341e-11,\n",
       "               2.0436e-11, 2.1033e-11]],\n",
       "     \n",
       "             ...,\n",
       "     \n",
       "             [[9.5040e-12, 9.2375e-12, 1.3831e-11,  ..., 1.6422e-11,\n",
       "               1.4125e-11, 1.2696e-11],\n",
       "              [5.0147e-12, 4.9650e-12, 4.8424e-12,  ..., 5.3303e-12,\n",
       "               5.0243e-12, 4.2629e-12],\n",
       "              [5.8219e-12, 5.7576e-12, 5.7782e-12,  ..., 5.1541e-12,\n",
       "               4.2353e-12, 3.4432e-12],\n",
       "              ...,\n",
       "              [5.5670e-11, 5.8903e-11, 6.1460e-11,  ..., 6.7940e-11,\n",
       "               7.1519e-11, 7.4271e-11],\n",
       "              [4.3390e-12, 3.8128e-12, 3.3279e-12,  ..., 1.5748e-12,\n",
       "               1.2023e-12, 9.6782e-13],\n",
       "              [1.7919e-11, 1.7571e-11, 1.7511e-11,  ..., 1.8307e-11,\n",
       "               1.8110e-11, 1.5964e-11]],\n",
       "     \n",
       "             [[5.6316e-11, 4.3595e-11, 4.1560e-11,  ..., 1.3151e-11,\n",
       "               1.5883e-11, 1.6229e-11],\n",
       "              [7.4974e-12, 7.7655e-12, 7.3447e-12,  ..., 4.0995e-12,\n",
       "               3.8594e-12, 3.5747e-12],\n",
       "              [7.7806e-12, 5.3800e-12, 4.1882e-12,  ..., 2.7310e-12,\n",
       "               2.6986e-12, 2.7217e-12],\n",
       "              ...,\n",
       "              [4.9426e-12, 5.3260e-12, 7.9435e-12,  ..., 2.0955e-11,\n",
       "               1.9752e-11, 1.8559e-11],\n",
       "              [3.1495e-12, 2.9651e-12, 2.9838e-12,  ..., 3.2453e-12,\n",
       "               3.3122e-12, 3.3615e-12],\n",
       "              [1.1112e-11, 1.1096e-11, 1.0778e-11,  ..., 1.1735e-11,\n",
       "               1.2884e-11, 1.3930e-11]],\n",
       "     \n",
       "             [[1.4497e-12, 1.4702e-12, 1.2471e-12,  ..., 1.8598e-12,\n",
       "               1.9148e-12, 3.3789e-12],\n",
       "              [8.3547e-13, 8.5345e-13, 8.6194e-13,  ..., 7.3885e-13,\n",
       "               6.7697e-13, 6.2517e-13],\n",
       "              [1.9259e-12, 1.6877e-12, 1.4698e-12,  ..., 7.9887e-13,\n",
       "               6.6717e-13, 5.8937e-13],\n",
       "              ...,\n",
       "              [7.1731e-13, 6.9371e-13, 6.6508e-13,  ..., 5.5766e-13,\n",
       "               5.1084e-13, 4.7205e-13],\n",
       "              [1.0753e-12, 9.3351e-13, 7.9466e-13,  ..., 4.7821e-13,\n",
       "               4.9247e-13, 4.6527e-13],\n",
       "              [2.3696e-12, 2.3392e-12, 2.3044e-12,  ..., 1.9565e-12,\n",
       "               1.7254e-12, 1.5322e-12]]])},\n",
       "    9: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-1.8883e-10, -2.4852e-11,  4.8958e-11, -3.2438e-11,  9.1061e-12,\n",
       "             -2.9735e-12, -3.2114e-11,  1.9796e-10,  2.7359e-11, -6.2898e-11,\n",
       "             -2.2689e-11, -1.4605e-11, -1.1265e-10,  3.4311e-11,  8.7419e-11,\n",
       "              4.1184e-12,  6.3320e-11, -1.0463e-10,  3.4940e-11, -4.9660e-11,\n",
       "             -3.2670e-10,  9.6051e-11,  2.3009e-12, -3.6575e-11, -1.1614e-10,\n",
       "             -3.2153e-11,  1.4441e-10, -1.5661e-10,  1.1736e-10,  4.6934e-11,\n",
       "             -2.0330e-11,  1.8592e-12, -4.8013e-11,  9.3195e-11,  3.8631e-10,\n",
       "              3.5474e-10,  2.1097e-10, -1.1431e-12,  2.6462e-10,  3.6525e-11,\n",
       "              7.3493e-11, -2.0803e-10, -1.2195e-10, -1.9967e-10,  7.9169e-10,\n",
       "              2.2770e-10, -1.3368e-12, -7.9409e-11, -2.5010e-10,  1.3823e-10,\n",
       "              9.8047e-11, -1.1993e-09, -7.0132e-11,  1.1326e-10,  2.2372e-11,\n",
       "             -4.8645e-12,  1.2313e-10,  1.1805e-11, -5.7348e-11, -5.5371e-11,\n",
       "              3.1997e-12,  2.5542e-10, -9.1119e-11, -5.8895e-11]),\n",
       "     'exp_avg_sq': tensor([6.7912e-19, 7.2695e-20, 8.6053e-19, 7.7764e-20, 2.5612e-18, 7.3066e-20,\n",
       "             6.2093e-20, 8.0441e-19, 3.4218e-19, 3.6209e-19, 6.6251e-20, 1.9082e-20,\n",
       "             2.8679e-19, 6.8090e-19, 1.8296e-20, 4.7624e-20, 2.4241e-19, 1.0930e-18,\n",
       "             1.7352e-20, 7.6084e-20, 1.1917e-18, 2.3422e-19, 1.7343e-19, 2.0057e-19,\n",
       "             4.4503e-20, 1.7564e-19, 9.4620e-19, 1.5953e-19, 2.4441e-19, 1.0044e-18,\n",
       "             3.0293e-19, 7.4557e-19, 3.4292e-19, 9.2622e-20, 4.8300e-19, 2.3068e-18,\n",
       "             4.8584e-19, 3.6260e-20, 1.2907e-18, 4.8814e-20, 4.1737e-19, 1.1898e-18,\n",
       "             9.6708e-19, 3.6485e-19, 3.2469e-18, 8.7611e-19, 5.4029e-20, 3.4104e-19,\n",
       "             1.4799e-18, 4.8405e-19, 2.9095e-19, 1.1329e-17, 9.8447e-19, 4.4984e-19,\n",
       "             2.4266e-20, 1.1700e-20, 6.1674e-18, 1.7509e-19, 1.8659e-19, 1.5627e-19,\n",
       "             3.0971e-20, 9.7885e-19, 1.1100e-18, 6.5433e-20])},\n",
       "    10: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-2.4337e-06, -2.1810e-06, -1.5057e-06, -4.7071e-06,  9.7227e-07,\n",
       "              1.8876e-06, -6.1180e-08,  3.3469e-06,  8.3974e-07, -6.9803e-07,\n",
       "              8.2894e-08, -1.4081e-07,  1.1153e-06, -5.1606e-06, -1.1527e-07,\n",
       "             -1.3612e-06, -5.2904e-06,  9.9245e-07,  1.2084e-06, -1.9537e-06,\n",
       "             -3.4525e-06, -2.5893e-06, -1.7331e-06, -9.9845e-07, -5.1952e-07,\n",
       "             -4.4777e-07, -2.9645e-06, -1.8095e-06, -1.2566e-06, -1.9197e-06,\n",
       "              1.1884e-06,  3.3144e-07, -6.6118e-07, -1.9686e-06, -1.8969e-06,\n",
       "             -7.2228e-06, -3.7794e-06,  5.1680e-07, -8.3287e-07, -1.9520e-08,\n",
       "             -4.7445e-06,  4.6586e-07, -2.5682e-06,  7.9618e-07,  1.3291e-05,\n",
       "              2.0382e-07, -1.6207e-06, -1.3269e-06,  2.7105e-07, -2.2932e-06,\n",
       "              3.3338e-07,  3.7632e-06, -2.2073e-07,  4.6867e-07, -4.4642e-07,\n",
       "              3.3186e-07,  3.2273e-06, -2.6908e-06, -1.7477e-06, -2.1750e-06,\n",
       "             -4.4255e-07, -5.6510e-06, -2.0322e-06,  1.4121e-07]),\n",
       "     'exp_avg_sq': tensor([7.3054e-10, 6.4498e-10, 7.2474e-10, 1.6732e-09, 6.2863e-10, 8.0730e-10,\n",
       "             1.1844e-09, 5.8189e-09, 1.2689e-10, 1.2713e-09, 1.2636e-10, 2.7586e-10,\n",
       "             1.2430e-09, 4.3493e-09, 1.3710e-10, 6.7148e-11, 7.4029e-09, 6.0406e-10,\n",
       "             1.4740e-10, 6.8481e-10, 8.6515e-09, 1.4827e-09, 5.4146e-10, 8.1644e-11,\n",
       "             1.9344e-11, 3.1821e-10, 9.3068e-10, 1.3247e-09, 1.0483e-09, 8.9386e-10,\n",
       "             4.0374e-10, 4.2729e-11, 2.2357e-09, 3.0647e-10, 1.3384e-08, 2.0416e-09,\n",
       "             2.7562e-09, 6.8030e-11, 1.2643e-09, 8.6133e-10, 4.6107e-09, 7.7450e-09,\n",
       "             9.8738e-10, 7.8566e-10, 4.1174e-09, 5.2380e-10, 2.6262e-10, 1.7987e-10,\n",
       "             1.0384e-09, 2.4573e-09, 3.1791e-09, 2.2205e-08, 4.6519e-10, 1.4028e-09,\n",
       "             1.0075e-11, 4.8383e-10, 8.8474e-09, 1.5552e-09, 2.1705e-09, 2.4018e-09,\n",
       "             1.5316e-10, 5.8759e-09, 1.7963e-09, 7.6162e-11])},\n",
       "    11: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-1.1808e-06, -2.0493e-06, -3.0756e-06, -3.1952e-06,  1.0548e-07,\n",
       "              1.6381e-06,  4.0165e-07,  2.7712e-06,  2.2686e-07, -3.0719e-07,\n",
       "             -2.6021e-07, -9.2596e-07,  6.0968e-07, -4.0147e-06, -3.4229e-07,\n",
       "             -1.0592e-06, -5.7828e-06,  2.3387e-06,  3.2204e-07, -5.7595e-07,\n",
       "             -6.1851e-06, -4.6892e-06, -2.0587e-07, -8.5709e-07, -4.3224e-07,\n",
       "             -5.5053e-07, -2.0142e-06, -6.4386e-06, -2.6232e-06, -2.4352e-06,\n",
       "              9.3036e-07,  3.4818e-07, -2.9100e-06, -1.3898e-06, -2.9832e-06,\n",
       "             -7.5456e-06, -2.4319e-06, -3.1340e-07, -4.0358e-06, -6.0043e-07,\n",
       "             -8.9759e-06, -1.4995e-07, -2.5287e-06, -1.9064e-06,  1.2259e-05,\n",
       "              1.4134e-06, -1.6547e-06, -1.9226e-06, -9.0091e-08, -5.8748e-06,\n",
       "              6.4009e-07,  7.4473e-06, -1.3886e-06, -1.3255e-06, -1.4759e-07,\n",
       "             -7.0022e-07,  1.1392e-06, -1.1250e-06, -4.2821e-08, -3.2602e-06,\n",
       "             -2.7608e-07, -2.5339e-06, -1.2848e-06,  3.4266e-07]),\n",
       "     'exp_avg_sq': tensor([3.1557e-10, 7.9465e-10, 2.1230e-09, 1.8855e-09, 7.6258e-10, 2.2747e-10,\n",
       "             3.5979e-09, 6.0542e-09, 3.5080e-11, 3.9718e-10, 7.0869e-11, 1.5041e-10,\n",
       "             3.5766e-09, 3.6454e-09, 4.6073e-11, 5.4320e-11, 2.2226e-08, 1.3098e-09,\n",
       "             1.6096e-11, 5.5940e-10, 2.5312e-08, 4.2693e-09, 1.2061e-11, 4.5729e-11,\n",
       "             1.1319e-11, 3.3675e-11, 3.7541e-10, 1.1877e-09, 2.1774e-09, 1.0161e-09,\n",
       "             2.2232e-10, 2.2201e-11, 2.0173e-09, 5.6744e-10, 7.8071e-09, 2.2383e-09,\n",
       "             1.0034e-09, 2.4323e-11, 1.5240e-09, 2.7431e-10, 1.5003e-08, 1.3949e-08,\n",
       "             1.0622e-09, 4.2291e-10, 3.6037e-09, 9.2344e-10, 1.3069e-10, 1.3260e-10,\n",
       "             1.3689e-09, 1.0708e-08, 3.9805e-09, 1.9026e-08, 5.1428e-10, 2.9021e-09,\n",
       "             2.1392e-12, 1.6010e-10, 3.9457e-09, 2.0017e-09, 7.3714e-11, 6.5747e-09,\n",
       "             5.5154e-11, 3.5899e-09, 9.3046e-10, 1.8350e-11])},\n",
       "    12: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[-1.6599e-07,  1.4966e-06,  6.7831e-07,  ...,  3.1986e-08,\n",
       "               8.1629e-08,  1.7401e-07],\n",
       "             [-1.7138e-06,  1.1881e-06,  3.3972e-06,  ..., -9.0599e-08,\n",
       "              -5.4861e-07, -2.3303e-07],\n",
       "             [ 2.3333e-06,  3.0622e-06,  2.6063e-06,  ..., -1.2606e-06,\n",
       "              -1.2642e-06, -1.3354e-06]]),\n",
       "     'exp_avg_sq': tensor([[9.8268e-11, 2.1398e-10, 1.3206e-10,  ..., 5.1481e-10, 6.5758e-10,\n",
       "              8.3659e-10],\n",
       "             [2.8427e-10, 9.1194e-10, 5.4310e-10,  ..., 1.1828e-09, 1.5798e-09,\n",
       "              2.1132e-09],\n",
       "             [1.8688e-10, 5.1549e-10, 2.7701e-10,  ..., 1.7760e-10, 2.5097e-10,\n",
       "              3.6193e-10]])},\n",
       "    13: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([4.2889e-06, 7.6624e-07, 3.7635e-06]),\n",
       "     'exp_avg_sq': tensor([8.2096e-10, 4.1777e-09, 1.7521e-09])},\n",
       "    14: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[-1.2177e-05,  5.7873e-06, -3.9196e-05],\n",
       "             [ 5.6830e-06,  2.3188e-05,  2.5116e-05],\n",
       "             [ 1.5166e-05,  1.3995e-05,  3.0847e-05],\n",
       "             [-1.2268e-05, -1.8872e-05, -3.1366e-05],\n",
       "             [ 7.5721e-06,  1.7572e-05,  1.8319e-05],\n",
       "             [ 1.7427e-05, -2.1960e-05, -2.3419e-05],\n",
       "             [ 1.7240e-05,  2.4012e-06,  1.7545e-05],\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "             [-3.0780e-05,  3.5852e-06, -3.5801e-05],\n",
       "             [ 1.1376e-06,  2.1595e-06,  5.8390e-05],\n",
       "             [-5.7316e-06, -3.9408e-06, -5.2718e-06],\n",
       "             [-1.8883e-05,  1.0502e-05,  2.6728e-05],\n",
       "             [ 1.0205e-05,  1.1091e-07,  7.0884e-06],\n",
       "             [-2.0374e-05,  6.1273e-06,  7.0634e-06],\n",
       "             [ 2.4643e-05,  1.8409e-05,  2.1379e-05],\n",
       "             [-6.3010e-06, -4.5442e-05, -5.7519e-05]]),\n",
       "     'exp_avg_sq': tensor([[2.9786e-08, 2.1519e-08, 7.4718e-08],\n",
       "             [6.9632e-08, 8.3477e-09, 1.9282e-08],\n",
       "             [3.8599e-08, 2.6042e-08, 5.2313e-08],\n",
       "             [2.5174e-08, 4.4636e-08, 1.7514e-07],\n",
       "             [1.9123e-09, 6.4968e-09, 8.5084e-09],\n",
       "             [1.2030e-08, 2.2167e-08, 4.6506e-08],\n",
       "             [4.5437e-08, 1.4588e-08, 5.6891e-08],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "             [3.0861e-08, 3.2147e-08, 5.0494e-08],\n",
       "             [1.8483e-07, 1.1255e-07, 9.8787e-08],\n",
       "             [2.5703e-08, 2.4762e-08, 2.9126e-08],\n",
       "             [4.6956e-08, 7.4642e-08, 1.6371e-07],\n",
       "             [6.5455e-09, 5.9962e-09, 1.7095e-09],\n",
       "             [3.9819e-08, 3.3432e-08, 1.5069e-08],\n",
       "             [1.7828e-08, 1.5683e-08, 4.3387e-08],\n",
       "             [6.7797e-08, 8.3069e-08, 1.0813e-07]])},\n",
       "    15: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-4.7693e-05,  1.3255e-05, -2.0585e-06, -4.3366e-05,  1.4898e-05,\n",
       "             -4.9416e-05,  2.8577e-05,  0.0000e+00, -2.2766e-05,  1.1689e-04,\n",
       "              1.9590e-05,  5.1826e-05, -1.1172e-05,  6.2197e-06,  1.7557e-05,\n",
       "             -8.6814e-05]),\n",
       "     'exp_avg_sq': tensor([1.3647e-07, 1.3346e-07, 2.4223e-07, 2.6047e-07, 4.7510e-08, 1.2566e-07,\n",
       "             1.2984e-07, 0.0000e+00, 1.7800e-07, 1.0675e-06, 1.3772e-07, 4.6759e-07,\n",
       "             1.5246e-08, 1.3186e-07, 1.0686e-07, 5.4482e-07])},\n",
       "    16: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[-1.7985e-07, -5.6052e-45,  3.7144e-08,  ...,  3.0876e-07,\n",
       "              -6.0051e-08,  9.3056e-09],\n",
       "             [ 6.8250e-07,  2.6582e-06,  8.9688e-07,  ...,  5.4759e-07,\n",
       "               9.4815e-07,  8.3505e-06],\n",
       "             [-1.0305e-06,  4.6909e-07, -1.8112e-06,  ..., -1.6321e-08,\n",
       "              -8.7926e-07,  3.3038e-06],\n",
       "             ...,\n",
       "             [ 9.4853e-07, -6.3280e-07, -5.4856e-06,  ..., -4.6123e-06,\n",
       "              -2.4916e-06, -4.1013e-06],\n",
       "             [ 1.1972e-06,  5.9419e-07,  4.2980e-07,  ...,  3.5198e-07,\n",
       "               4.8352e-07,  2.5802e-06],\n",
       "             [-2.7829e-06,  5.5820e-07,  3.1336e-06,  ...,  9.2923e-07,\n",
       "               7.5207e-07,  1.7400e-06]]),\n",
       "     'exp_avg_sq': tensor([[2.8853e-11, 3.1048e-34, 4.5714e-10,  ..., 5.1676e-10, 1.3994e-10,\n",
       "              1.1395e-14],\n",
       "             [5.0042e-10, 3.3765e-10, 3.7547e-10,  ..., 4.4389e-10, 2.0504e-10,\n",
       "              1.8608e-09],\n",
       "             [3.0102e-11, 4.8494e-10, 1.8459e-10,  ..., 9.1523e-13, 4.4594e-11,\n",
       "              3.2694e-09],\n",
       "             ...,\n",
       "             [1.9463e-10, 8.2256e-12, 1.4878e-09,  ..., 8.3076e-10, 5.9924e-10,\n",
       "              1.4605e-09],\n",
       "             [3.3144e-11, 1.4191e-11, 2.0749e-11,  ..., 1.8153e-11, 9.5644e-12,\n",
       "              6.1560e-11],\n",
       "             [3.3204e-09, 4.9280e-10, 1.3428e-08,  ..., 1.9571e-08, 5.2738e-09,\n",
       "              1.2675e-08]])},\n",
       "    17: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-3.9150e-07,  1.1076e-05, -2.5902e-06,  7.0646e-05, -1.6936e-05,\n",
       "              2.9885e-05,  1.5091e-05,  5.6052e-45, -1.1227e-07, -2.3931e-05,\n",
       "              0.0000e+00,  3.1531e-05,  5.6052e-45, -6.6228e-06, -3.0008e-06,\n",
       "              3.2701e-05,  4.1900e-05,  1.5948e-04,  3.7594e-05, -2.6186e-05,\n",
       "             -6.6915e-05,  5.6052e-45,  1.6388e-05,  1.4808e-28,  1.2176e-05,\n",
       "              0.0000e+00,  5.0622e-09,  4.9951e-06, -2.4955e-05,  0.0000e+00,\n",
       "              5.6052e-45,  8.0698e-05, -3.3918e-06,  3.5861e-05, -7.5645e-05,\n",
       "              0.0000e+00,  5.6052e-45,  0.0000e+00, -6.8503e-05, -4.3824e-05,\n",
       "              0.0000e+00,  0.0000e+00,  1.6227e-05, -4.3668e-05, -3.0901e-05,\n",
       "              2.5266e-06,  9.7560e-06, -5.7670e-06, -1.0952e-05, -2.7836e-06,\n",
       "              0.0000e+00,  5.7343e-06,  8.8667e-06,  6.5759e-07, -4.8308e-05,\n",
       "              4.4408e-06,  7.4102e-06,  1.3069e-06,  2.0196e-05,  5.4919e-06,\n",
       "             -8.6032e-06, -1.4199e-05,  6.5495e-06,  1.4160e-05]),\n",
       "     'exp_avg_sq': tensor([1.4829e-09, 1.1821e-08, 1.0764e-08, 4.9515e-07, 1.4478e-08, 3.4571e-08,\n",
       "             3.3864e-08, 4.7732e-12, 7.5013e-08, 1.5782e-08, 0.0000e+00, 5.1770e-07,\n",
       "             5.6888e-26, 4.4323e-09, 4.2669e-09, 1.5505e-07, 1.4368e-07, 5.8265e-06,\n",
       "             9.3476e-08, 7.2293e-08, 1.0135e-07, 5.8964e-35, 1.1571e-08, 1.7362e-11,\n",
       "             2.0183e-08, 0.0000e+00, 1.0188e-10, 2.2169e-08, 1.0264e-07, 0.0000e+00,\n",
       "             2.3652e-29, 1.4109e-06, 1.6061e-08, 6.4091e-08, 3.7071e-07, 0.0000e+00,\n",
       "             8.3275e-34, 0.0000e+00, 5.4601e-08, 4.6043e-08, 0.0000e+00, 0.0000e+00,\n",
       "             1.3090e-07, 7.9918e-08, 5.0371e-08, 6.6553e-09, 4.4830e-09, 4.4194e-09,\n",
       "             3.7763e-08, 3.2910e-08, 0.0000e+00, 8.1372e-08, 6.9290e-10, 3.3600e-08,\n",
       "             7.4588e-08, 6.0915e-08, 2.8843e-08, 4.5022e-09, 1.9141e-08, 4.2325e-08,\n",
       "             1.8746e-08, 1.1814e-08, 9.8251e-10, 1.8814e-07])},\n",
       "    18: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[ 5.6052e-45,  5.6727e-08,  4.0577e-08,  ...,  7.0604e-09,\n",
       "               4.3059e-10, -1.6894e-08],\n",
       "             [ 5.7145e-16,  1.3033e-07,  1.9042e-09,  ..., -3.0997e-08,\n",
       "               8.5224e-09,  3.0119e-07],\n",
       "             [ 0.0000e+00,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             ...,\n",
       "             [ 2.0354e-07,  2.4381e-07, -1.5548e-08,  ...,  4.5466e-07,\n",
       "              -2.7906e-08,  2.5309e-06],\n",
       "             [-4.1906e-11,  9.6496e-12, -2.6586e-12,  ..., -1.9812e-11,\n",
       "               2.1156e-09, -1.7716e-09],\n",
       "             [-5.6052e-45, -1.1458e-06, -3.7700e-07,  ..., -2.5096e-07,\n",
       "              -2.9131e-08, -1.1298e-07]]),\n",
       "     'exp_avg_sq': tensor([[3.9067e-26, 3.1320e-12, 1.9614e-12,  ..., 1.1663e-14, 1.6669e-15,\n",
       "              5.9764e-14],\n",
       "             [2.8026e-17, 7.6631e-13, 1.5541e-14,  ..., 2.3766e-13, 6.4529e-14,\n",
       "              1.2256e-11],\n",
       "             [0.0000e+00, 1.5019e-38, 8.4353e-38,  ..., 2.3716e-38, 1.4965e-37,\n",
       "              1.7474e-39],\n",
       "             ...,\n",
       "             [2.7749e-12, 3.0969e-11, 2.5869e-11,  ..., 7.1353e-12, 1.7363e-12,\n",
       "              4.2873e-10],\n",
       "             [1.8573e-15, 1.1828e-15, 8.0884e-16,  ..., 2.0498e-16, 9.1486e-17,\n",
       "              2.4474e-15],\n",
       "             [2.7756e-29, 3.4425e-11, 1.8044e-11,  ..., 1.1698e-12, 1.0248e-12,\n",
       "              7.7412e-11]])},\n",
       "    19: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 3.6468e-06,  3.1352e-06,  5.6052e-45, -5.5567e-08,  0.0000e+00,\n",
       "              2.8712e-05,  0.0000e+00,  8.8742e-06,  2.7559e-05,  0.0000e+00,\n",
       "              3.6501e-05, -6.0246e-06,  1.2805e-05,  3.7722e-05, -2.8550e-06,\n",
       "             -3.0996e-06,  3.1416e-06,  6.5249e-07, -7.3508e-06,  4.5022e-05,\n",
       "              3.0163e-06, -6.7684e-08,  5.6025e-06, -2.1954e-06,  2.1591e-06,\n",
       "              7.9046e-19, -2.2589e-06,  0.0000e+00,  5.6052e-45, -2.7276e-07,\n",
       "              0.0000e+00,  5.6052e-45, -9.7274e-07,  1.3355e-05,  1.5479e-05,\n",
       "              5.6052e-45,  5.6052e-45,  1.4498e-06, -1.1885e-06,  3.7588e-05,\n",
       "             -1.4335e-05,  4.9570e-06,  2.8611e-07,  5.6052e-45,  2.4361e-05,\n",
       "              3.6114e-05,  0.0000e+00,  8.2852e-06, -3.3506e-06,  3.0695e-06,\n",
       "              0.0000e+00,  5.6052e-45, -1.1173e-06, -2.5763e-06, -4.7571e-06,\n",
       "              5.6052e-45, -6.2489e-06, -2.0190e-07, -3.5288e-06,  0.0000e+00,\n",
       "              5.6052e-45,  0.0000e+00,  9.6406e-07,  3.2728e-07,  2.8503e-05,\n",
       "              3.9374e-05, -3.2541e-07,  4.4749e-06,  5.4495e-06,  5.6052e-45,\n",
       "              2.4307e-07,  5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,\n",
       "             -1.8376e-06, -5.7917e-06,  7.7890e-06,  5.6052e-45,  5.6052e-45,\n",
       "              0.0000e+00, -4.2909e-07,  0.0000e+00,  5.6052e-45,  3.6404e-06,\n",
       "              3.1159e-06,  4.4759e-07,  3.7261e-05,  4.2197e-06, -1.1438e-05,\n",
       "              2.6714e-06,  0.0000e+00, -1.9113e-06, -1.6232e-06,  0.0000e+00,\n",
       "              1.6394e-05,  5.6052e-45, -6.5416e-06,  5.6052e-45,  5.6052e-45,\n",
       "             -1.4017e-05, -7.8524e-06, -1.5346e-05, -5.2956e-07,  0.0000e+00,\n",
       "              0.0000e+00,  9.1018e-06, -4.9401e-07,  0.0000e+00,  0.0000e+00,\n",
       "              3.9274e-05,  0.0000e+00,  5.9788e-06,  6.6430e-07,  0.0000e+00,\n",
       "              5.6052e-45,  3.6820e-05,  6.7680e-06,  1.1026e-05, -5.5769e-06,\n",
       "              2.5081e-07,  9.7705e-06,  3.6319e-06,  1.9785e-09,  7.4004e-06,\n",
       "              3.0285e-05,  5.6052e-45, -1.5448e-06,  0.0000e+00,  2.1261e-05,\n",
       "              2.1653e-05,  0.0000e+00,  4.7849e-06, -1.4271e-06,  3.8997e-05,\n",
       "              5.6052e-45,  0.0000e+00,  1.2437e-05,  5.6052e-45,  0.0000e+00,\n",
       "             -9.8500e-07,  5.6052e-45, -6.7513e-06,  5.6052e-45,  6.8557e-06,\n",
       "             -2.8919e-07,  5.6052e-45,  1.6646e-05,  3.6551e-05,  5.6052e-45,\n",
       "              1.4093e-06,  1.4446e-06, -5.2670e-07,  0.0000e+00,  0.0000e+00,\n",
       "              3.4967e-05, -9.0217e-06, -4.5716e-07,  5.6052e-45,  6.6125e-06,\n",
       "              5.6052e-45,  5.6052e-45,  4.8743e-06, -1.5768e-06,  3.6607e-05,\n",
       "              0.0000e+00,  1.7063e-05,  0.0000e+00,  3.6740e-06,  6.8892e-06,\n",
       "              5.6052e-45, -2.4656e-06,  1.6289e-05, -2.8538e-06,  3.6652e-06,\n",
       "              5.6052e-45,  0.0000e+00,  5.6052e-45, -3.6070e-06,  3.9299e-05,\n",
       "              0.0000e+00,  3.5581e-05, -9.5959e-06,  5.6052e-45,  3.0428e-05,\n",
       "              5.3294e-06,  4.5054e-05,  3.5303e-05,  5.6052e-45,  1.7849e-06,\n",
       "              5.6052e-45,  5.6052e-45, -5.3068e-06,  3.7587e-05,  3.3959e-05,\n",
       "             -1.1069e-06, -4.8851e-06,  2.9428e-05,  3.1800e-05,  7.2050e-06,\n",
       "             -5.0542e-06, -1.2350e-05,  8.5211e-06,  5.6052e-45, -8.4496e-08,\n",
       "             -4.7048e-07, -1.4244e-06,  5.6052e-45,  8.4125e-07,  4.3502e-05,\n",
       "              0.0000e+00, -4.6055e-07,  5.6052e-45,  1.7627e-05,  5.6052e-45,\n",
       "             -5.1626e-07,  1.9108e-06,  5.5155e-06, -1.8357e-06, -2.5193e-06,\n",
       "              1.8330e-05, -3.9604e-05,  1.6463e-05,  5.6052e-45,  9.8992e-06,\n",
       "              5.6052e-45,  1.7286e-05, -1.0805e-05,  5.6052e-45,  3.1275e-05,\n",
       "              5.6052e-45,  5.6052e-45,  0.0000e+00,  5.6052e-45, -3.9703e-06,\n",
       "              3.3543e-05,  1.7570e-05,  3.8841e-05,  0.0000e+00,  5.6052e-45,\n",
       "              1.4441e-06,  5.6052e-45,  5.6052e-45, -2.2978e-06,  3.0277e-05,\n",
       "              2.6203e-05,  5.6052e-45, -5.7140e-06,  2.2239e-05,  7.8486e-06,\n",
       "              4.7157e-05,  2.0301e-06, -7.2763e-07,  3.0039e-05, -3.2272e-07,\n",
       "              2.9286e-05]),\n",
       "     'exp_avg_sq': tensor([2.8537e-09, 1.4309e-09, 1.5318e-36, 2.0150e-10, 0.0000e+00, 1.2313e-07,\n",
       "             0.0000e+00, 2.9602e-08, 7.0549e-08, 0.0000e+00, 1.8915e-07, 3.2965e-08,\n",
       "             2.4613e-08, 1.7386e-07, 1.4194e-10, 1.8162e-09, 1.5463e-09, 3.6883e-09,\n",
       "             1.7814e-08, 2.6583e-07, 1.1292e-07, 1.4117e-10, 1.4362e-10, 2.8872e-09,\n",
       "             1.4737e-10, 2.9033e-12, 4.9175e-10, 0.0000e+00, 1.5385e-15, 6.0426e-11,\n",
       "             0.0000e+00, 2.8914e-20, 2.8171e-11, 5.6138e-08, 2.8433e-09, 7.6334e-35,\n",
       "             1.3812e-19, 8.4103e-11, 2.7964e-11, 2.6894e-07, 2.9358e-08, 2.6244e-09,\n",
       "             3.9604e-11, 5.4083e-17, 1.3629e-08, 2.1867e-07, 0.0000e+00, 2.3309e-09,\n",
       "             4.3817e-11, 2.0379e-09, 0.0000e+00, 1.5438e-27, 1.5848e-11, 9.3568e-11,\n",
       "             4.3228e-10, 7.7834e-34, 8.7525e-09, 5.6961e-11, 2.1201e-07, 0.0000e+00,\n",
       "             3.8294e-26, 0.0000e+00, 3.4267e-10, 3.5321e-11, 1.0407e-07, 1.4348e-07,\n",
       "             7.5505e-09, 1.0753e-07, 6.0796e-09, 1.6400e-36, 1.9322e-11, 6.3398e-28,\n",
       "             0.0000e+00, 0.0000e+00, 7.4518e-27, 1.0774e-10, 6.2490e-10, 4.1195e-10,\n",
       "             1.7639e-13, 6.0110e-32, 0.0000e+00, 8.9234e-11, 0.0000e+00, 1.3231e-33,\n",
       "             4.4146e-09, 1.9715e-11, 5.4751e-11, 1.3319e-07, 8.8248e-10, 3.2276e-09,\n",
       "             8.5183e-11, 0.0000e+00, 4.1816e-11, 7.1887e-11, 0.0000e+00, 1.0464e-07,\n",
       "             1.8600e-32, 1.9806e-08, 2.0886e-18, 7.6173e-24, 7.4213e-08, 2.1790e-09,\n",
       "             1.6209e-07, 2.2022e-09, 0.0000e+00, 0.0000e+00, 3.2840e-07, 5.9170e-08,\n",
       "             0.0000e+00, 0.0000e+00, 3.0151e-07, 0.0000e+00, 4.7900e-08, 6.0239e-11,\n",
       "             0.0000e+00, 6.7187e-34, 1.0953e-07, 1.0827e-08, 2.8521e-07, 8.9115e-10,\n",
       "             2.1218e-11, 2.1017e-08, 4.7381e-09, 1.4628e-11, 2.6329e-09, 1.8137e-07,\n",
       "             1.0639e-28, 4.0855e-11, 0.0000e+00, 3.7326e-08, 8.9609e-08, 0.0000e+00,\n",
       "             1.4232e-09, 1.3529e-10, 2.4406e-07, 2.2132e-23, 0.0000e+00, 1.1083e-07,\n",
       "             4.9848e-31, 0.0000e+00, 2.1740e-10, 3.6604e-27, 1.2656e-07, 6.4313e-29,\n",
       "             2.6671e-09, 1.0746e-10, 3.2890e-34, 2.0298e-08, 1.7216e-07, 7.2704e-23,\n",
       "             3.9413e-10, 1.3484e-08, 1.9228e-08, 0.0000e+00, 0.0000e+00, 1.7240e-07,\n",
       "             3.6577e-09, 6.1030e-10, 2.1296e-29, 2.5615e-09, 3.8498e-27, 1.6630e-36,\n",
       "             2.5634e-09, 4.2168e-09, 2.4130e-07, 0.0000e+00, 3.1314e-07, 0.0000e+00,\n",
       "             6.9635e-10, 1.2137e-09, 2.6563e-16, 2.4583e-10, 6.1697e-09, 9.0366e-10,\n",
       "             4.2380e-10, 1.3698e-25, 0.0000e+00, 1.6070e-34, 6.7599e-10, 2.4673e-07,\n",
       "             0.0000e+00, 9.7174e-08, 2.9870e-09, 1.6330e-19, 9.8815e-08, 1.9661e-07,\n",
       "             3.2921e-07, 1.3890e-07, 3.8600e-16, 1.9432e-11, 1.2941e-16, 2.0574e-19,\n",
       "             7.2666e-09, 2.8009e-07, 1.8220e-07, 8.7007e-11, 2.5995e-10, 1.2472e-07,\n",
       "             2.6058e-07, 1.4186e-08, 6.8118e-10, 7.5146e-08, 9.8865e-09, 1.2338e-25,\n",
       "             9.6852e-09, 1.9932e-11, 2.5375e-08, 1.5288e-27, 8.0598e-11, 2.6873e-07,\n",
       "             0.0000e+00, 1.2113e-10, 4.7416e-34, 1.5988e-07, 2.5023e-19, 3.6107e-11,\n",
       "             9.4153e-11, 1.8577e-09, 4.9861e-10, 7.3499e-10, 2.6333e-08, 3.7130e-08,\n",
       "             5.3074e-08, 3.3839e-28, 4.7663e-08, 5.8280e-34, 2.0088e-08, 1.5774e-08,\n",
       "             9.8356e-36, 1.4332e-07, 7.3343e-19, 1.1941e-30, 0.0000e+00, 1.4068e-23,\n",
       "             2.8858e-09, 1.1470e-07, 7.6492e-08, 2.3782e-07, 0.0000e+00, 6.8154e-21,\n",
       "             8.6550e-11, 1.1764e-31, 3.3769e-16, 1.2190e-09, 1.2852e-07, 2.1739e-07,\n",
       "             1.9609e-27, 9.7374e-09, 6.0127e-08, 1.2862e-07, 2.8762e-07, 5.7852e-10,\n",
       "             8.3347e-10, 1.2144e-07, 1.4925e-11, 3.1481e-08])},\n",
       "    20: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[ 5.0313e-08,  1.6181e-07,  5.6052e-45,  ...,  1.1502e-06,\n",
       "               4.9498e-08,  9.8114e-07],\n",
       "             [ 2.7081e-08,  3.0707e-08, -5.6052e-45,  ...,  1.4016e-06,\n",
       "               4.3232e-08,  4.1867e-07],\n",
       "             [-4.4930e-08, -6.4178e-08, -5.6052e-45,  ...,  6.1714e-07,\n",
       "              -3.8568e-09, -1.8428e-07],\n",
       "             ...,\n",
       "             [ 1.4094e-07,  3.3200e-08, -5.6052e-45,  ...,  5.8409e-07,\n",
       "               1.9415e-09,  3.0670e-07],\n",
       "             [ 1.5770e-07,  3.3152e-08, -5.6052e-45,  ...,  9.6674e-07,\n",
       "               4.5272e-09,  5.2510e-07],\n",
       "             [ 1.5960e-07,  1.5305e-08, -5.6052e-45,  ...,  1.2963e-06,\n",
       "               6.1212e-09,  7.0400e-07]]),\n",
       "     'exp_avg_sq': tensor([[5.5870e-13, 1.9885e-13, 8.8001e-40,  ..., 3.4385e-11, 9.8259e-15,\n",
       "              7.0364e-12],\n",
       "             [2.9875e-13, 1.2732e-13, 2.6359e-40,  ..., 2.5052e-11, 6.0562e-15,\n",
       "              4.8981e-12],\n",
       "             [2.4104e-13, 9.9127e-14, 3.3455e-40,  ..., 2.4529e-11, 5.6735e-15,\n",
       "              4.5720e-12],\n",
       "             ...,\n",
       "             [2.0682e-13, 7.6937e-14, 1.0383e-40,  ..., 1.6164e-11, 3.5620e-15,\n",
       "              2.9888e-12],\n",
       "             [2.1993e-13, 8.2332e-14, 7.4762e-41,  ..., 1.6588e-11, 3.7112e-15,\n",
       "              3.1562e-12],\n",
       "             [2.6652e-13, 9.9329e-14, 6.1322e-41,  ..., 1.7805e-11, 4.1938e-15,\n",
       "              3.5421e-12]])},\n",
       "    21: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([ 6.3294e-06,  1.0319e-05,  4.7689e-06, -2.6888e-06, -1.2305e-06,\n",
       "              6.3922e-06,  6.6728e-06, -1.1459e-06, -4.2376e-06,  3.1154e-06,\n",
       "              8.1293e-06,  1.3607e-06, -4.4816e-06, -1.8528e-06,  4.4835e-06,\n",
       "              6.0849e-06,  2.3808e-06,  2.6341e-08,  3.2132e-06,  7.0737e-06,\n",
       "              5.6205e-06,  2.7731e-06,  3.0854e-06,  6.6182e-06,  5.5013e-06,\n",
       "              9.8285e-07, -1.7566e-06, -1.0648e-06,  1.1316e-06,  4.0027e-06,\n",
       "              5.4751e-06,  6.1612e-06,  5.7414e-06,  5.7343e-06,  5.7040e-06,\n",
       "              4.9697e-06,  3.5390e-06,  2.0640e-06,  1.4014e-06,  1.8360e-06,\n",
       "              2.8384e-06,  4.3106e-06,  4.7468e-06,  4.6494e-06,  3.6197e-06,\n",
       "              2.5720e-06,  2.5543e-06,  2.8608e-06,  3.5869e-06,  4.1063e-06,\n",
       "              4.5689e-06,  4.3630e-06,  3.9269e-06,  3.3167e-06,  2.9514e-06,\n",
       "              2.5197e-06,  2.1411e-06,  2.0589e-06,  1.9776e-06,  2.2932e-06,\n",
       "              2.9258e-06,  3.5668e-06,  4.0539e-06,  4.0854e-06,  3.5112e-06,\n",
       "              2.6958e-06,  1.9152e-06,  1.2429e-06,  8.0602e-07,  8.6855e-07,\n",
       "              1.2642e-06,  1.9641e-06,  2.6553e-06,  3.0841e-06,  2.5712e-06,\n",
       "              2.0013e-06,  1.1034e-06,  7.0483e-07,  1.7653e-07, -1.1757e-07,\n",
       "              1.0562e-07,  5.9964e-07,  1.6501e-06,  2.5884e-06,  3.2706e-06,\n",
       "              3.9358e-06,  4.2939e-06,  3.9642e-06,  3.5609e-06,  2.8020e-06,\n",
       "              2.3860e-06,  1.8883e-06,  1.5729e-06,  1.4778e-06,  1.9053e-06,\n",
       "              2.1282e-06,  2.3954e-06,  2.9091e-06,  3.2816e-06,  3.5120e-06,\n",
       "              3.5016e-06,  3.3291e-06,  2.8962e-06,  2.3443e-06,  1.7974e-06,\n",
       "              1.1897e-06,  8.2113e-07,  5.3767e-07,  2.8995e-07,  4.4533e-07,\n",
       "              7.4824e-07,  1.0525e-06,  1.6787e-06,  2.0049e-06,  2.5279e-06,\n",
       "              2.8235e-06,  3.0099e-06,  2.9409e-06,  3.1409e-06,  3.0397e-06,\n",
       "              2.5423e-06,  2.3548e-06,  2.0096e-06,  1.5242e-06,  1.4304e-06,\n",
       "              1.0979e-06,  1.0870e-06,  9.6799e-07,  7.5423e-07,  7.6145e-07,\n",
       "              8.4472e-07,  7.3160e-07,  7.0957e-07,  9.0860e-07,  9.2422e-07,\n",
       "              1.0944e-06,  1.2115e-06,  1.4392e-06,  1.5600e-06,  1.4570e-06,\n",
       "              1.7782e-06,  1.8292e-06,  1.7132e-06,  1.8455e-06,  1.7623e-06,\n",
       "              1.6941e-06,  1.8589e-06,  1.4253e-06,  1.5292e-06,  1.4294e-06,\n",
       "              1.2946e-06,  1.1606e-06,  2.3786e-06,  3.7066e-06,  3.6218e-06,\n",
       "              2.3303e-06,  5.5074e-07, -5.5869e-07, -3.1491e-07,  9.1153e-07,\n",
       "              2.2578e-06,  3.1352e-06,  2.7636e-06,  2.1393e-06,  1.1180e-06,\n",
       "              5.5355e-07,  4.8318e-07,  6.4976e-07,  8.9946e-07,  1.1054e-06,\n",
       "              1.0560e-06,  1.3361e-06,  1.5104e-06,  1.8937e-06,  1.7716e-06,\n",
       "              1.7041e-06,  1.2193e-06,  9.1017e-07,  5.1620e-07,  4.9809e-07,\n",
       "              1.2111e-06,  2.1635e-06,  2.4727e-06,  2.6369e-06,  2.0777e-06,\n",
       "              1.6153e-06,  1.0535e-06,  7.2301e-07,  1.0730e-06,  1.3619e-06,\n",
       "              1.8016e-06,  1.8382e-06,  1.7102e-06,  1.5704e-06,  1.3930e-06,\n",
       "              1.4388e-06,  1.7217e-06,  2.1051e-06,  2.3938e-06,  2.7118e-06,\n",
       "              2.1250e-06,  1.0840e-06,  3.0014e-07, -5.1321e-07, -6.6960e-07,\n",
       "             -2.8033e-07,  1.8368e-07,  9.3390e-07,  1.5075e-06,  1.6916e-06,\n",
       "              1.4415e-06,  6.2586e-07,  3.2294e-08, -6.0275e-07, -1.0265e-06,\n",
       "             -7.5249e-07, -2.7960e-07,  4.3541e-07,  1.2935e-06,  1.7621e-06,\n",
       "              1.9170e-06,  1.7873e-06,  1.3270e-06,  6.4502e-07,  7.3256e-08,\n",
       "             -5.6806e-07, -7.3745e-07, -9.6986e-07, -6.6486e-07, -1.7946e-07,\n",
       "              3.4768e-07,  9.5579e-07,  1.0017e-06,  1.0818e-06,  6.7913e-07,\n",
       "              1.3296e-07, -5.3947e-07, -6.2041e-07, -8.7620e-07, -7.6788e-07,\n",
       "             -4.8139e-07,  1.4489e-08,  6.5222e-07,  1.0898e-06,  1.2582e-06,\n",
       "              1.2045e-06,  8.7432e-07,  4.6303e-07, -8.2163e-08, -3.8202e-07,\n",
       "             -6.6396e-07, -4.4178e-07,  4.0128e-09,  3.3164e-07,  9.6096e-07,\n",
       "              1.2689e-06,  1.3448e-06,  1.3305e-06,  9.0017e-07,  4.1028e-07,\n",
       "             -1.8067e-07, -6.9410e-07, -8.8480e-07, -8.2031e-07, -6.2969e-07,\n",
       "             -2.6474e-09,  2.8715e-07,  8.0755e-07,  1.0623e-06,  1.1573e-06,\n",
       "              8.6303e-07,  6.8234e-07,  1.9328e-07, -4.5519e-07, -7.5550e-07,\n",
       "             -9.5001e-07, -8.3104e-07, -6.2289e-07, -6.7205e-08,  4.0845e-07,\n",
       "              8.4340e-07,  1.1621e-06,  1.3488e-06,  1.3301e-06,  1.1011e-06,\n",
       "              4.8820e-07, -4.9782e-08, -4.5093e-07, -7.5916e-07, -1.0183e-06,\n",
       "             -8.7616e-07, -7.8516e-07, -4.8566e-07, -1.7933e-07,  2.8498e-07,\n",
       "              6.9988e-07,  9.3402e-07,  1.0212e-06,  9.8737e-07,  1.1434e-06,\n",
       "              1.0772e-06,  1.0330e-06,  7.4706e-07,  7.5692e-07,  7.3495e-07,\n",
       "              9.4858e-07,  1.0934e-06,  1.2448e-06,  1.1782e-06,  1.2850e-06,\n",
       "              1.0212e-06,  7.2450e-07,  1.1120e-07, -1.9335e-07, -5.8285e-07,\n",
       "             -7.0354e-07, -7.5633e-07, -6.9733e-07, -4.2072e-07, -1.3217e-07,\n",
       "              4.1187e-07,  8.8483e-07,  1.3477e-06,  1.7467e-06,  1.6922e-06,\n",
       "              1.4983e-06,  1.1318e-06,  5.1909e-07, -2.8507e-07, -1.1373e-06,\n",
       "             -2.1369e-06, -2.6136e-06, -3.4274e-06, -3.5312e-06, -3.1025e-06,\n",
       "             -2.5091e-06, -1.3545e-06,  6.9493e-07,  2.9111e-06,  5.4788e-06,\n",
       "              8.7705e-06,  1.1656e-05,  1.3774e-05]),\n",
       "     'exp_avg_sq': tensor([2.2197e-09, 1.6159e-09, 1.5361e-09, 1.4100e-09, 1.3012e-09, 1.2390e-09,\n",
       "             1.3960e-09, 1.4143e-09, 1.3811e-09, 1.4101e-09, 1.4706e-09, 1.2988e-09,\n",
       "             1.2810e-09, 1.2779e-09, 1.2769e-09, 1.2874e-09, 1.2077e-09, 1.2277e-09,\n",
       "             1.2868e-09, 1.3488e-09, 1.4324e-09, 1.4752e-09, 1.4756e-09, 1.5680e-09,\n",
       "             1.6509e-09, 1.5654e-09, 1.4056e-09, 1.3010e-09, 1.1897e-09, 1.1131e-09,\n",
       "             1.0265e-09, 8.8281e-10, 7.5776e-10, 7.2269e-10, 6.9057e-10, 6.8199e-10,\n",
       "             6.9261e-10, 6.7799e-10, 6.6026e-10, 6.5955e-10, 6.9111e-10, 7.0885e-10,\n",
       "             7.0426e-10, 7.0671e-10, 6.9462e-10, 6.7438e-10, 6.3640e-10, 6.1392e-10,\n",
       "             6.0744e-10, 6.2033e-10, 6.1008e-10, 6.0435e-10, 5.7848e-10, 5.8096e-10,\n",
       "             5.7923e-10, 5.7304e-10, 5.8628e-10, 5.8865e-10, 5.9191e-10, 5.9397e-10,\n",
       "             6.0416e-10, 6.0494e-10, 6.3029e-10, 6.4605e-10, 6.2770e-10, 6.0538e-10,\n",
       "             6.0484e-10, 5.8886e-10, 5.9815e-10, 6.1784e-10, 6.2807e-10, 6.2137e-10,\n",
       "             6.2509e-10, 6.4269e-10, 6.1822e-10, 5.9496e-10, 5.6779e-10, 5.6583e-10,\n",
       "             5.5709e-10, 5.6820e-10, 5.7257e-10, 5.9957e-10, 6.1656e-10, 6.2050e-10,\n",
       "             6.3996e-10, 6.2225e-10, 6.2244e-10, 6.1535e-10, 6.2282e-10, 5.9597e-10,\n",
       "             5.9021e-10, 5.8466e-10, 5.9653e-10, 5.8352e-10, 5.8681e-10, 6.0632e-10,\n",
       "             6.2984e-10, 6.1785e-10, 6.3855e-10, 6.1639e-10, 6.4097e-10, 6.2825e-10,\n",
       "             6.5432e-10, 6.5207e-10, 6.3404e-10, 6.5584e-10, 6.3677e-10, 6.5668e-10,\n",
       "             6.7117e-10, 6.4874e-10, 6.8448e-10, 6.7527e-10, 6.7494e-10, 6.7165e-10,\n",
       "             6.8668e-10, 6.7317e-10, 6.7844e-10, 7.2286e-10, 6.9192e-10, 7.0283e-10,\n",
       "             7.2376e-10, 7.3206e-10, 7.3234e-10, 7.2929e-10, 7.0523e-10, 7.1329e-10,\n",
       "             7.1067e-10, 6.7531e-10, 6.9048e-10, 7.1484e-10, 7.0770e-10, 6.9464e-10,\n",
       "             7.1462e-10, 7.1222e-10, 7.2835e-10, 7.1769e-10, 7.2446e-10, 7.3161e-10,\n",
       "             7.0985e-10, 7.1877e-10, 7.1768e-10, 6.9355e-10, 6.9761e-10, 6.8827e-10,\n",
       "             6.9672e-10, 7.0202e-10, 7.0613e-10, 7.1855e-10, 7.2618e-10, 7.3798e-10,\n",
       "             6.9830e-10, 7.2146e-10, 6.9872e-10, 6.7926e-10, 6.5965e-10, 6.3948e-10,\n",
       "             6.2354e-10, 6.6749e-10, 6.4641e-10, 6.5325e-10, 6.7589e-10, 6.5944e-10,\n",
       "             6.2491e-10, 6.4986e-10, 6.7816e-10, 6.7595e-10, 7.0477e-10, 6.8163e-10,\n",
       "             7.1388e-10, 7.0683e-10, 6.9305e-10, 7.0083e-10, 7.2100e-10, 7.1973e-10,\n",
       "             7.0918e-10, 6.8143e-10, 6.8526e-10, 6.6826e-10, 6.8426e-10, 6.7371e-10,\n",
       "             6.4589e-10, 6.2080e-10, 5.9753e-10, 6.2767e-10, 6.3896e-10, 6.4475e-10,\n",
       "             6.3680e-10, 6.4847e-10, 6.3525e-10, 6.4550e-10, 6.3447e-10, 6.3483e-10,\n",
       "             6.3467e-10, 6.2666e-10, 6.1405e-10, 6.1332e-10, 6.2686e-10, 5.8804e-10,\n",
       "             5.8015e-10, 5.7542e-10, 5.6127e-10, 5.7433e-10, 5.6343e-10, 5.8380e-10,\n",
       "             5.8154e-10, 5.8988e-10, 5.7810e-10, 5.6802e-10, 5.7010e-10, 5.7432e-10,\n",
       "             5.5194e-10, 5.8327e-10, 5.6613e-10, 5.7064e-10, 5.7872e-10, 5.7049e-10,\n",
       "             5.6253e-10, 5.6820e-10, 5.7100e-10, 5.9403e-10, 6.0652e-10, 5.9441e-10,\n",
       "             5.9466e-10, 5.8796e-10, 5.5251e-10, 5.7031e-10, 5.4376e-10, 5.7371e-10,\n",
       "             5.6026e-10, 5.6370e-10, 5.5580e-10, 5.8114e-10, 5.3928e-10, 5.6572e-10,\n",
       "             5.4065e-10, 5.5005e-10, 5.3338e-10, 5.4933e-10, 5.2092e-10, 5.3766e-10,\n",
       "             5.3903e-10, 5.4013e-10, 5.4776e-10, 5.3142e-10, 5.3667e-10, 5.1771e-10,\n",
       "             5.3973e-10, 5.4340e-10, 5.3675e-10, 5.4995e-10, 5.4001e-10, 5.4495e-10,\n",
       "             5.4060e-10, 5.3180e-10, 5.2608e-10, 5.3096e-10, 5.0338e-10, 5.3566e-10,\n",
       "             5.2926e-10, 5.4737e-10, 5.5319e-10, 5.4243e-10, 5.4216e-10, 5.4130e-10,\n",
       "             5.4630e-10, 5.4208e-10, 5.2136e-10, 5.3405e-10, 5.3133e-10, 5.1541e-10,\n",
       "             5.2678e-10, 5.1440e-10, 5.3670e-10, 5.3656e-10, 5.4455e-10, 5.3931e-10,\n",
       "             5.4239e-10, 5.5104e-10, 5.5069e-10, 5.2480e-10, 5.3714e-10, 5.3845e-10,\n",
       "             5.3421e-10, 5.4098e-10, 5.3510e-10, 5.4327e-10, 5.5913e-10, 5.2986e-10,\n",
       "             5.3934e-10, 5.3997e-10, 5.4376e-10, 5.4297e-10, 5.4608e-10, 5.3218e-10,\n",
       "             5.4496e-10, 5.5125e-10, 5.6235e-10, 5.7925e-10, 5.5602e-10, 5.6371e-10,\n",
       "             5.5387e-10, 5.6397e-10, 5.4379e-10, 5.3627e-10, 5.2972e-10, 5.4054e-10,\n",
       "             5.5027e-10, 5.4781e-10, 5.4961e-10, 5.6443e-10, 5.6155e-10, 5.7367e-10,\n",
       "             5.9860e-10, 6.1603e-10, 6.1241e-10, 6.1783e-10, 6.0854e-10, 6.0182e-10,\n",
       "             5.6819e-10, 5.5308e-10, 5.7274e-10, 5.7733e-10, 5.9695e-10, 6.1310e-10,\n",
       "             6.0720e-10, 6.3351e-10, 6.4971e-10, 6.6362e-10, 6.9621e-10, 7.5010e-10,\n",
       "             7.8255e-10, 7.8567e-10, 7.8998e-10, 7.5978e-10, 7.5836e-10, 7.8717e-10,\n",
       "             8.1936e-10, 8.8053e-10, 9.7066e-10, 1.0214e-09, 1.0733e-09, 1.1034e-09,\n",
       "             1.1781e-09])},\n",
       "    22: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[ 6.0121e-05,  1.6337e-04, -2.8070e-04],\n",
       "             [ 9.1509e-06,  1.3768e-04,  1.9300e-04],\n",
       "             [-1.1684e-04,  1.5936e-04,  7.1926e-04]]),\n",
       "     'exp_avg_sq': tensor([[3.4655e-06, 2.5987e-06, 3.1440e-05],\n",
       "             [2.2804e-06, 1.7516e-06, 2.9890e-05],\n",
       "             [4.2819e-06, 9.3879e-07, 2.6066e-05]])},\n",
       "    23: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([-1.1560e-05,  7.7273e-06, -3.9555e-05]),\n",
       "     'exp_avg_sq': tensor([8.9778e-08, 6.8299e-08, 5.0725e-08])},\n",
       "    24: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([[-1.0375e-06, -5.2249e-07, -2.6774e-06]]),\n",
       "     'exp_avg_sq': tensor([[3.4260e-11, 1.2511e-11, 2.5969e-10]])},\n",
       "    25: {'step': tensor(44068.),\n",
       "     'exp_avg': tensor([1.5681e-07]),\n",
       "     'exp_avg_sq': tensor([9.1888e-13])}},\n",
       "   'param_groups': [{'lr': 0.001,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0.0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23,\n",
       "      24,\n",
       "      25]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'MixedPrecision': {'scale': 1048576.0,\n",
       "  'growth_factor': 2.0,\n",
       "  'backoff_factor': 0.5,\n",
       "  'growth_interval': 2000,\n",
       "  '_growth_tracker': 126},\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'_class_path': 'spherinator.models.VariationalAutoencoderPure',\n",
       "  'encoder': {'class_path': 'spherinator.models.ConvolutionalEncoder1DGen',\n",
       "   'init_args': {'input_dim': [1, 343],\n",
       "    'output_dim': 3,\n",
       "    'cnn_layers': [{'class_path': 'spherinator.models.ConsecutiveConv1DLayer',\n",
       "      'init_args': {'kernel_size': 5,\n",
       "       'stride': 1,\n",
       "       'padding': 0,\n",
       "       'num_layers': 1,\n",
       "       'base_channel_number': 16,\n",
       "       'channel_increment': 4,\n",
       "       'activation': {'class_path': 'torch.nn.ReLU'},\n",
       "       'norm': {'class_path': 'torch.nn.BatchNorm1d',\n",
       "        'init_args': {'eps': 1e-05,\n",
       "         'momentum': 0.1,\n",
       "         'affine': True,\n",
       "         'track_running_stats': True,\n",
       "         'device': None,\n",
       "         'dtype': None}},\n",
       "       'pooling': {'class_path': 'torch.nn.MaxPool1d',\n",
       "        'init_args': {'kernel_size': 2,\n",
       "         'stride': None,\n",
       "         'padding': 0,\n",
       "         'dilation': 1,\n",
       "         'return_indices': False,\n",
       "         'ceil_mode': True}}}},\n",
       "     {'class_path': 'spherinator.models.ConsecutiveConv1DLayer',\n",
       "      'init_args': {'kernel_size': 7,\n",
       "       'stride': 1,\n",
       "       'padding': 0,\n",
       "       'num_layers': 1,\n",
       "       'base_channel_number': 32,\n",
       "       'channel_increment': 4,\n",
       "       'activation': {'class_path': 'torch.nn.ReLU'},\n",
       "       'norm': {'class_path': 'torch.nn.BatchNorm1d',\n",
       "        'init_args': {'eps': 1e-05,\n",
       "         'momentum': 0.1,\n",
       "         'affine': True,\n",
       "         'track_running_stats': True,\n",
       "         'device': None,\n",
       "         'dtype': None}},\n",
       "       'pooling': {'class_path': 'torch.nn.MaxPool1d',\n",
       "        'init_args': {'kernel_size': 2,\n",
       "         'stride': None,\n",
       "         'padding': 0,\n",
       "         'dilation': 1,\n",
       "         'return_indices': False,\n",
       "         'ceil_mode': True}}}},\n",
       "     {'class_path': 'spherinator.models.ConsecutiveConv1DLayer',\n",
       "      'init_args': {'kernel_size': 9,\n",
       "       'stride': 1,\n",
       "       'padding': 0,\n",
       "       'num_layers': 1,\n",
       "       'base_channel_number': 64,\n",
       "       'channel_increment': 4,\n",
       "       'activation': {'class_path': 'torch.nn.ReLU'},\n",
       "       'norm': {'class_path': 'torch.nn.BatchNorm1d',\n",
       "        'init_args': {'eps': 1e-05,\n",
       "         'momentum': 0.1,\n",
       "         'affine': True,\n",
       "         'track_running_stats': True,\n",
       "         'device': None,\n",
       "         'dtype': None}},\n",
       "       'pooling': {'class_path': 'torch.nn.MaxPool1d',\n",
       "        'init_args': {'kernel_size': 2,\n",
       "         'stride': None,\n",
       "         'padding': 0,\n",
       "         'dilation': 1,\n",
       "         'return_indices': False,\n",
       "         'ceil_mode': True}}}}]}},\n",
       "  'decoder': {'class_path': 'spherinator.models.DenseModel',\n",
       "   'init_args': {'layer_dims': [3, 16, 64, 256, 343],\n",
       "    'output_shape': [1, 343],\n",
       "    'activation': {'class_path': 'torch.nn.ReLU'}}},\n",
       "  'z_dim': 3,\n",
       "  'beta': 0.001,\n",
       "  '_instantiator': 'lightning.pytorch.cli.instantiate_module'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = artifact_dir + \"/model.ckpt\"\n",
    "checkpoint = torch.load(ckpt, weights_only=True, map_location=\"cpu\")\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[0.4591, 0.2237, 0.8598]], grad_fn=<DivBackward0>),\n",
       "  tensor([[28595.6230]], grad_fn=<AddBackward0>)),\n",
       " (PowerSpherical(loc: torch.Size([1, 3]), scale: 28595.623046875),\n",
       "  HypersphericalUniform(dim=3, device=cpu, dtype=torch.float32)),\n",
       " tensor([[0.4589, 0.2186, 0.8612]], grad_fn=<SubBackward0>),\n",
       " tensor([[[0.6207, 0.4858, 0.3959, 0.3607, 0.3641, 0.3616, 0.3613, 0.3652,\n",
       "           0.3752, 0.4023, 0.3976, 0.3729, 0.3686, 0.3563, 0.3445, 0.3453,\n",
       "           0.3618, 0.3660, 0.3776, 0.3762, 0.3822, 0.3880, 0.4031, 0.4006,\n",
       "           0.3978, 0.3815, 0.3635, 0.3408, 0.3238, 0.3041, 0.3024, 0.2992,\n",
       "           0.3080, 0.3232, 0.3221, 0.3169, 0.2967, 0.2794, 0.2766, 0.2874,\n",
       "           0.2904, 0.2997, 0.3000, 0.2941, 0.2813, 0.2687, 0.2594, 0.2528,\n",
       "           0.2441, 0.2426, 0.2381, 0.2463, 0.2625, 0.2752, 0.2848, 0.2973,\n",
       "           0.3009, 0.3041, 0.3037, 0.2983, 0.3063, 0.3085, 0.3073, 0.3094,\n",
       "           0.3094, 0.3090, 0.3047, 0.2930, 0.2887, 0.2780, 0.2765, 0.2668,\n",
       "           0.2655, 0.2560, 0.2488, 0.2447, 0.2463, 0.2417, 0.2496, 0.2504,\n",
       "           0.2578, 0.2600, 0.2588, 0.2602, 0.2584, 0.2471, 0.2401, 0.2341,\n",
       "           0.2263, 0.2257, 0.2231, 0.2310, 0.2343, 0.2480, 0.2571, 0.2634,\n",
       "           0.2700, 0.2783, 0.2729, 0.2796, 0.2765, 0.2687, 0.2651, 0.2593,\n",
       "           0.2663, 0.2636, 0.2657, 0.2639, 0.2693, 0.2703, 0.2633, 0.2702,\n",
       "           0.2725, 0.2679, 0.2652, 0.2676, 0.2666, 0.2617, 0.2674, 0.2706,\n",
       "           0.2652, 0.2636, 0.2565, 0.2583, 0.2600, 0.2532, 0.2494, 0.2551,\n",
       "           0.2499, 0.2470, 0.2475, 0.2503, 0.2508, 0.2485, 0.2446, 0.2459,\n",
       "           0.2446, 0.2409, 0.2407, 0.2454, 0.2431, 0.2405, 0.2376, 0.2378,\n",
       "           0.2456, 0.2437, 0.2483, 0.2518, 0.2555, 0.2680, 0.2685, 0.2699,\n",
       "           0.2856, 0.2943, 0.2996, 0.2977, 0.2954, 0.2991, 0.3023, 0.3076,\n",
       "           0.2937, 0.2940, 0.2950, 0.2905, 0.2945, 0.2899, 0.2845, 0.2780,\n",
       "           0.2673, 0.2611, 0.2632, 0.2656, 0.2676, 0.2649, 0.2636, 0.2609,\n",
       "           0.2626, 0.2668, 0.2669, 0.2772, 0.2865, 0.2954, 0.2943, 0.2952,\n",
       "           0.2970, 0.2915, 0.2877, 0.2825, 0.2778, 0.2676, 0.2632, 0.2613,\n",
       "           0.2715, 0.2749, 0.2879, 0.2901, 0.2926, 0.2979, 0.2938, 0.2976,\n",
       "           0.2956, 0.2958, 0.2997, 0.2991, 0.2960, 0.2937, 0.2942, 0.2967,\n",
       "           0.2941, 0.2958, 0.2970, 0.3018, 0.3047, 0.3013, 0.2974, 0.2958,\n",
       "           0.2931, 0.2927, 0.2875, 0.2915, 0.2903, 0.2877, 0.2879, 0.2924,\n",
       "           0.2867, 0.2830, 0.2871, 0.2818, 0.2886, 0.2907, 0.2906, 0.2845,\n",
       "           0.2858, 0.2738, 0.2788, 0.2643, 0.2703, 0.2627, 0.2667, 0.2577,\n",
       "           0.2585, 0.2528, 0.2556, 0.2516, 0.2476, 0.2534, 0.2513, 0.2539,\n",
       "           0.2546, 0.2511, 0.2607, 0.2616, 0.2631, 0.2662, 0.2599, 0.2565,\n",
       "           0.2598, 0.2552, 0.2557, 0.2461, 0.2501, 0.2484, 0.2481, 0.2456,\n",
       "           0.2396, 0.2395, 0.2451, 0.2410, 0.2325, 0.2381, 0.2387, 0.2415,\n",
       "           0.2394, 0.2410, 0.2414, 0.2444, 0.2413, 0.2327, 0.2318, 0.2318,\n",
       "           0.2294, 0.2285, 0.2228, 0.2243, 0.2220, 0.2195, 0.2216, 0.2223,\n",
       "           0.2169, 0.2147, 0.2098, 0.2142, 0.2123, 0.2129, 0.2150, 0.2086,\n",
       "           0.2073, 0.2075, 0.2136, 0.2163, 0.2165, 0.2173, 0.2237, 0.2160,\n",
       "           0.2199, 0.2136, 0.2104, 0.2094, 0.2066, 0.2027, 0.2103, 0.2120,\n",
       "           0.2106, 0.2087, 0.2074, 0.2098, 0.2125, 0.2128, 0.2128, 0.2218,\n",
       "           0.2146, 0.2130, 0.2134, 0.2143, 0.2165, 0.2162, 0.2158, 0.2265,\n",
       "           0.2260, 0.2329, 0.2406, 0.2489, 0.2564, 0.2679, 0.2728, 0.2830,\n",
       "           0.2992, 0.3126, 0.3304, 0.3531, 0.3823, 0.3995, 0.4396]]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1, 1, 343)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:101: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/readability.py:52: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  new_node = self.module.graph.get_attr(normalized_name)\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1801: UserWarning: Node encoder_cnn_0_0_1_running_mean target encoder/cnn/0/0/1/running_mean encoder/cnn/0/0/1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1801: UserWarning: Node encoder_cnn_0_0_1_running_var target encoder/cnn/0/0/1/running_var encoder/cnn/0/0/1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1801: UserWarning: Node encoder_cnn_1_0_1_running_mean target encoder/cnn/1/0/1/running_mean encoder/cnn/1/0/1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1801: UserWarning: Node encoder_cnn_1_0_1_running_var target encoder/cnn/1/0/1/running_var encoder/cnn/1/0/1/running_var of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1801: UserWarning: Node encoder_cnn_2_0_1_running_mean target encoder/cnn/2/0/1/running_mean encoder/cnn/2/0/1/running_mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/fx/graph.py:1810: UserWarning: Additional 1 warnings suppressed about get_attr references\n",
      "  warnings.warn(\n",
      "/home/doserbd/.cache/pypoetry/virtualenvs/spherinator-zzYPp9oG-py3.12/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:101: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 2 of general pattern rewrite rules.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"gaia-calibrated-v0\", exist_ok=True)\n",
    "\n",
    "export_options = torch.onnx.ExportOptions(dynamic_shapes=True)\n",
    "onnx = torch.onnx.dynamo_export(model.variational_encoder, torch.randn(1, 1, 343, device=\"cpu\"), export_options=export_options)\n",
    "onnx.save(\"gaia-calibrated-v0/encoder.onnx\")\n",
    "\n",
    "onnx = torch.onnx.dynamo_export(model.decoder, torch.randn(1, 3, device=\"cpu\"), export_options=export_options)\n",
    "onnx.save(\"gaia-calibrated-v0/decoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorized uses only. All activity may be monitored and reported.\n",
      "skipping directory gaia-calibrated-v0\n"
     ]
    }
   ],
   "source": [
    "!rsync gaia-calibrated-v0 space:/var/www/html/space/models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spherinator-zzYPp9oG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
